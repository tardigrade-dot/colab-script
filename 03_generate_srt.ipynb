{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Is1MrBMf0c6L"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gzKAg107LnW7"
      },
      "source": [
        "å®‰è£…sensevoiceç¯å¢ƒ"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OjP432I2KYA5"
      },
      "outputs": [],
      "source": [
        "!pip install -r https://raw.githubusercontent.com/FunAudioLLM/SenseVoice/refs/heads/main/requirements.txt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_iWFkR2HG79J"
      },
      "outputs": [],
      "source": [
        "!pip install wetext"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_6E-XaOWLs2N"
      },
      "outputs": [],
      "source": [
        "# sv311 å®‰è£…SenseVoiceç¯å¢ƒ: https://github.com/FunAudioLLM/SenseVoice\n",
        "\n",
        "import re\n",
        "import os\n",
        "from pathlib import Path\n",
        "import string\n",
        "from funasr import AutoModel\n",
        "import difflib\n",
        "from pydub import AudioSegment\n",
        "from wetext import Normalizer\n",
        "\n",
        "class CtcForcdAlign:\n",
        "    def __init__(self, model_dir, device) -> None:\n",
        "\n",
        "        self.MIN_CHARS_PER_LINE = 10 \n",
        "        self.model = AutoModel(\n",
        "            model=model_dir,\n",
        "            vad_model=\"fsmn-vad\",\n",
        "            vad_kwargs={\"max_single_segment_time\": 30_000},\n",
        "            device=device,\n",
        "            disable_update=True,\n",
        "            trust_remote_code=True,\n",
        "            # remote_code=\"./extro/model.py\",\n",
        "            remote_code=\"funasr.models.sense_voice.model\",\n",
        "        )\n",
        "\n",
        "        self.normalizer = Normalizer(lang=\"zh\", operator=\"tn\", remove_erhua=True, traditional_to_simple=True)\n",
        "        chinese_pattern = r\"ï¼ˆ.*?ï¼‰\"\n",
        "        english_pattern = r\"\\([^)]*?\\)\"\n",
        "\n",
        "        self.combined_pattern = f\"{chinese_pattern}|{english_pattern}\"\n",
        "        self.PUNCTUATION_CHARS = set(string.punctuation) | set(',.?ï¼Œã€‚ï¼ï¼Ÿï¼›ï¼šã€â€œâ€â€˜â€™ã€Šã€‹ã€ã€‘ï¼ˆï¼‰')\n",
        "        self.PUNCT_REGEX = re.compile(r'[.,:;!?ï¼Œã€‚ã€ï¼›ï¼šï¼Ÿï¼â€œâ€˜â€â€™ï¼ˆï¼‰ã€Šã€‹ã€ã€‘\\s-]')\n",
        "    \n",
        "    def is_punctuation(self, token):\n",
        "        return token in self.PUNCTUATION_CHARS\n",
        "    \n",
        "    def map_opcodes_to_raw(self, clean_opcodes, asr_timestamps, correct_tokens_raw):\n",
        "        aligned_timestamps = []\n",
        "        status = []\n",
        "        \n",
        "        j_raw_ptr = 0 \n",
        "        \n",
        "        for tag, i1, i2, j1, j2 in clean_opcodes:\n",
        "            \n",
        "            while j_raw_ptr < len(correct_tokens_raw) and self.PUNCT_REGEX.match(correct_tokens_raw[j_raw_ptr]):\n",
        "                aligned_timestamps.append((None, None))\n",
        "                j_raw_ptr += 1\n",
        "\n",
        "            asr_chars_consumed = i2 - i1\n",
        "            if tag == \"equal\":\n",
        "                for k in range(j2 - j1): # éå†åŒ¹é…çš„æ±‰å­—\n",
        "                    aligned_timestamps.append(asr_timestamps[i1 + k])\n",
        "                    status.append(True)\n",
        "                    j_raw_ptr += 1 # åŸå§‹æŒ‡é’ˆç§»åŠ¨ä¸€ä¸ªæ±‰å­—\n",
        "                    while j_raw_ptr < len(correct_tokens_raw) and self.PUNCT_REGEX.match(correct_tokens_raw[j_raw_ptr]):\n",
        "                        aligned_timestamps.append((None, None))\n",
        "                        j_raw_ptr += 1\n",
        "            elif tag == \"replace\" or tag == \"insert\":\n",
        "                for k in range(j2 - j1): # éå†å·®å¼‚çš„æ±‰å­—\n",
        "                    if asr_chars_consumed > 0:\n",
        "                        idx = i1 + k % asr_chars_consumed\n",
        "                        aligned_timestamps.append(asr_timestamps[idx])\n",
        "                    else: # çº¯ç²¹çš„æ’å…¥ (tag='insert')\n",
        "                        aligned_timestamps.append((None, None))\n",
        "                    status.append(False)\n",
        "                    j_raw_ptr += 1 # åŸå§‹æŒ‡é’ˆç§»åŠ¨ä¸€ä¸ªæ±‰å­—\n",
        "                    while j_raw_ptr < len(correct_tokens_raw) and self.PUNCT_REGEX.match(correct_tokens_raw[j_raw_ptr]):\n",
        "                        aligned_timestamps.append((None, None))\n",
        "                        j_raw_ptr += 1\n",
        "            elif tag == \"delete\":\n",
        "                continue\n",
        "\n",
        "        while j_raw_ptr < len(correct_tokens_raw) and self.PUNCT_REGEX.match(correct_tokens_raw[j_raw_ptr]):\n",
        "            aligned_timestamps.append((None, None))\n",
        "            j_raw_ptr += 1\n",
        "        if len(aligned_timestamps) == len(correct_tokens_raw):\n",
        "            return aligned_timestamps, status\n",
        "        else:\n",
        "            print(f\"ğŸš¨ è­¦å‘Š: æœ€ç»ˆé•¿åº¦ä¸åŒ¹é…. Raw: {len(correct_tokens_raw)}, Aligned: {len(aligned_timestamps)}\")\n",
        "            return aligned_timestamps, status\n",
        "        \n",
        "    def map_asr_to_correct(self, asr_tokens, asr_timestamps, correct_tokens):\n",
        "        \n",
        "        punctuation_regex = r'[.,:;!?ï¼Œã€‚ã€ï¼›ï¼šï¼Ÿï¼â€œâ€˜â€â€™ï¼ˆï¼‰ã€Šã€‹ã€ã€‘\\s-]'\n",
        "        clean_correct_tokens = re.sub(punctuation_regex, '', correct_tokens)\n",
        "        matcher_clean = difflib.SequenceMatcher(None, asr_tokens, clean_correct_tokens)\n",
        "        clean_opcodes = matcher_clean.get_opcodes()\n",
        "\n",
        "        return self.map_opcodes_to_raw(clean_opcodes, asr_timestamps, correct_tokens)\n",
        "\n",
        "    #old version\n",
        "    def map_asr_to_correct_oldversion(self, asr_tokens, asr_timestamps, correct_tokens):\n",
        "        \"\"\"\n",
        "        å°†ASR tokenæ—¶é—´æˆ³æ˜ å°„åˆ°æ­£ç¡®æ–‡æœ¬ token\n",
        "        è¿”å›ï¼š\n",
        "            aligned_timestamps: å¯¹é½åçš„æ­£ç¡®æ–‡æœ¬æ—¶é—´æˆ³åˆ—è¡¨\n",
        "            status: æ¯ä¸ª token æ˜¯å¦åŒ¹é…\n",
        "        \"\"\"\n",
        "        aligned_timestamps = []\n",
        "        status = []\n",
        "\n",
        "        # asr_tokens = \"\".join(asr_tokens)\n",
        "        # ä½¿ç”¨ difflib å¯¹é½ ASR ä¸æ­£ç¡®æ–‡æœ¬\n",
        "        matcher = difflib.SequenceMatcher(self.is_punctuation, asr_tokens, correct_tokens)\n",
        "        for tag, i1, i2, j1, j2 in matcher.get_opcodes():\n",
        "            if tag == \"equal\":\n",
        "                # token åŒ¹é… â†’ ç›´æ¥ç»§æ‰¿æ—¶é—´æˆ³\n",
        "                for k in range(j2 - j1):\n",
        "                    aligned_timestamps.append(asr_timestamps[i1 + k])\n",
        "                    status.append(True)\n",
        "            elif tag == \"replace\":\n",
        "                # token æ›¿æ¢ â†’ å°è¯•å¹³å‡åˆ†é…æ—¶é—´æˆ³\n",
        "                # å¯ä»¥é€‰æ‹©æ ‡è®°ä¸ºä¸åŒ¹é…\n",
        "                for k in range(j2 - j1):\n",
        "                    if (i2 - i1) > 0:\n",
        "                        idx = i1 + k % (i2 - i1)\n",
        "                        aligned_timestamps.append(asr_timestamps[idx])\n",
        "                    else:\n",
        "                        # ASR æ²¡æœ‰å¯¹åº” token â†’ å¡«å…… None\n",
        "                        aligned_timestamps.append((None, None))\n",
        "                    status.append(False)\n",
        "            elif tag == \"insert\":\n",
        "                # æ­£ç¡®æ–‡æœ¬ä¸­æ–°å¢ token â†’ æ— å¯¹åº” ASR token\n",
        "                for _ in range(j2 - j1):\n",
        "                    aligned_timestamps.append((None, None))\n",
        "                    status.append(False)\n",
        "            elif tag == \"delete\":\n",
        "                # ASR ä¸­å¤šä½™ token â†’ å¿½ç•¥\n",
        "                continue\n",
        "\n",
        "        return aligned_timestamps, status\n",
        "\n",
        "    def is_valid_time(self, t):\n",
        "        return isinstance(t, (int, float)) and t >= 0\n",
        "\n",
        "    def get_valid_start_end(self, words):\n",
        "        start_time, end_time = None, None\n",
        "\n",
        "        for w in words:\n",
        "            t = w.get('start')\n",
        "            if self.is_valid_time(t):\n",
        "                start_time = t\n",
        "                break\n",
        "\n",
        "        for w in reversed(words):\n",
        "            t = w.get('end')\n",
        "            if self.is_valid_time(t):\n",
        "                end_time = t\n",
        "                break\n",
        "\n",
        "        return start_time, end_time\n",
        "\n",
        "    def ms_to_srt_time_format(self, ms):\n",
        "        # ç¡®ä¿è¾“å…¥æ˜¯æ•´æ•°æˆ–å¯ä»¥è½¬æ¢ä¸ºæ•´æ•°\n",
        "        ms = int(ms)\n",
        "        # è®¡ç®—å°æ—¶ã€åˆ†é’Ÿã€ç§’å’Œæ¯«ç§’\n",
        "        hours = ms // 3600000\n",
        "        minutes = (ms % 3600000) // 60000\n",
        "        seconds = (ms % 60000) // 1000\n",
        "        milliseconds = ms % 1000\n",
        "\n",
        "        # ä½¿ç”¨ f-string æ ¼å¼åŒ–è¾“å‡ºï¼Œç¡®ä¿æ¯ä¸ªéƒ¨åˆ†éƒ½æœ‰å›ºå®šçš„ä½æ•°\n",
        "        return f\"{hours:02d}:{minutes:02d}:{seconds:02d},{milliseconds:03d}\"\n",
        "\n",
        "    def generate_srt_from_words_and_timestamps(self, words, timestamps):\n",
        "        if not words or not timestamps or len(words) != len(timestamps):\n",
        "            print(f\"words length[{len(words)}] not equal to timestamps length[{len(timestamps)}]\")\n",
        "            raise Exception('process error')\n",
        "\n",
        "        srt_content = \"\"\n",
        "        subtitle_index = 1\n",
        "        sentence_delimiters = ['ã€‚', 'ï¼Ÿ', 'ï¼', '.', '?', '!', 'â€¦']\n",
        "        \n",
        "        current_subtitle_words = [] \n",
        "        end_time = 0\n",
        "        \n",
        "        # å†…éƒ¨å‡½æ•°ï¼šè´Ÿè´£åˆ¤æ–­æ˜¯å¦æ»¡è¶³é•¿åº¦è¦æ±‚å¹¶è¾“å‡ºå­—å¹•\n",
        "        def _write_subtitle(words_to_write, pre_end_time):\n",
        "            nonlocal srt_content, subtitle_index\n",
        "            \n",
        "            if not words_to_write:\n",
        "                return None\n",
        "                \n",
        "            # start_time = words_to_write[0]['start']\n",
        "            # end_time = words_to_write[-1]['end']\n",
        "            try:\n",
        "\n",
        "                start_time, end_time = self.get_valid_start_end(words_to_write)\n",
        "                if pre_end_time and pre_end_time != 0 and start_time < pre_end_time:\n",
        "                    start_time = pre_end_time\n",
        "            except Exception as e:\n",
        "                raise Exception(f\"è·å–æœ‰æ•ˆæ—¶é—´æˆ³æ—¶å‡ºé”™, éŸ³é¢‘è´¨é‡å­˜åœ¨é—®é¢˜: {e}\")\n",
        "            \n",
        "            # å°†å•è¯åˆ—è¡¨ç»„åˆæˆä¸€ä¸ªå®Œæ•´çš„å¥å­\n",
        "            sentence_text = \"\".join([w['word'] for w in words_to_write])\n",
        "            \n",
        "            srt_content += str(subtitle_index) + \"\\n\"\n",
        "            srt_content += f\"{self.ms_to_srt_time_format(start_time)} --> {self.ms_to_srt_time_format(end_time)}\\n\"\n",
        "            srt_content += sentence_text + \"\\n\\n\"\n",
        "            subtitle_index += 1\n",
        "            return end_time\n",
        "        \n",
        "        for i in range(len(words)):\n",
        "            word = words[i]\n",
        "            timestamp = timestamps[i]\n",
        "            \n",
        "            current_subtitle_words.append({'word': word, 'start': timestamp[0], 'end': timestamp[1]})\n",
        "            \n",
        "            is_sentence_end = word in sentence_delimiters\n",
        "            if is_sentence_end:\n",
        "                current_text = \"\".join([w['word'] for w in current_subtitle_words])\n",
        "                current_length = len(current_text)\n",
        "                if current_length >= self.MIN_CHARS_PER_LINE:\n",
        "                    end_time = _write_subtitle(current_subtitle_words, end_time)\n",
        "                    current_subtitle_words = [] # æ¸…ç©ºç´¯è®¡åˆ—è¡¨\n",
        "        if current_subtitle_words:\n",
        "            all_none = all(\n",
        "                item['start'] is None and item['end'] is None\n",
        "                for item in current_subtitle_words\n",
        "            )\n",
        "            if not all_none:\n",
        "                _write_subtitle(current_subtitle_words, end_time)\n",
        "            \n",
        "        return srt_content\n",
        "\n",
        "    def generate_srt_file(self, wav_file, over_write=False):\n",
        "        \n",
        "        wav_path = Path(wav_file)\n",
        "        \n",
        "        txt_path = wav_path.with_suffix('.txt')\n",
        "        srt_path = wav_path.with_suffix('.srt')\n",
        "\n",
        "        txt_file = str(txt_path)\n",
        "        srt_file = str(srt_path)\n",
        "\n",
        "        print(f'\\nwav [{wav_file}], \\ntxt [{txt_file}], \\nsrt [{srt_file}]')\n",
        "\n",
        "        if not wav_path.exists():\n",
        "            raise Exception(f'wav file[{wav_file}] not exists ')\n",
        "        if not txt_path.exists():\n",
        "            raise Exception(f'txt file[{txt_file}] not exists ')\n",
        "        if srt_path.exists() and not over_write:\n",
        "            print(f'srt file[{srt_file}] exists, just return ')\n",
        "            return\n",
        "        \n",
        "        with open(txt_file, 'r') as f:\n",
        "            target_txt = \"\".join(f.readlines())\n",
        "\n",
        "        res = self.model.generate(\n",
        "                input=wav_file,\n",
        "                cache={},\n",
        "                language=\"auto\",  # \"zn\", \"en\", \"yue\", \"ja\", \"ko\", \"nospeech\"\n",
        "                use_itn=False,\n",
        "                batch_size_s=30,\n",
        "                merge_vad=True,\n",
        "                merge_length_s=20,\n",
        "                output_timestamp=True,\n",
        "            )\n",
        "        output = res[0]\n",
        "        \n",
        "        target_txt = re.sub(self.combined_pattern, \"\", target_txt)\n",
        "        target_txt = target_txt.replace(\"\\n\", \" \")\n",
        "        target_txt = self.normalizer.normalize(target_txt)\n",
        "        \n",
        "        aligned_timestamps, status = self.map_asr_to_correct(output[\"words\"], output[\"timestamp\"], target_txt)\n",
        "\n",
        "        num_tokens = len(status)\n",
        "        num_mismatch = status.count(False)\n",
        "        mismatch_ratio = num_mismatch / num_tokens\n",
        "\n",
        "        if mismatch_ratio > 0.05:\n",
        "            print(f\"âš ï¸ âŒ æ³¨æ„, ä¸åŒ¹é…ç‡è¿‡é«˜.  ä¸åŒ¹é… token({num_mismatch}/{num_tokens}) å æ¯”: {mismatch_ratio:.2%}\")\n",
        "        else:\n",
        "            print(f\"âš ï¸ âœ… ä¸åŒ¹é… token({num_mismatch}/{num_tokens}) å æ¯”: {mismatch_ratio:.2%}\")\n",
        "\n",
        "        srt_result = self.generate_srt_from_words_and_timestamps(target_txt, aligned_timestamps)\n",
        "        \n",
        "        with open(srt_file, 'w') as f:\n",
        "            f.write(srt_result)\n",
        "            \n",
        "        print(f\"å­—å¹•å·²ç”Ÿæˆ, ä¿å­˜åœ¨:{srt_file}\")\n",
        "\n",
        "    def get_wav_list_sorted(self, wav_src_dir, wav_regex=None):\n",
        "\n",
        "        if wav_regex is None:\n",
        "            wav_regex = r'.*-(\\d+)_(\\d+)\\.wav$'\n",
        "        pattern = re.compile(wav_regex)\n",
        "\n",
        "        files = [\n",
        "            f for f in os.listdir(wav_src_dir)\n",
        "            if f.endswith('.wav') and pattern.match(f)\n",
        "        ]\n",
        "\n",
        "        def sort_key(filename):\n",
        "            m = pattern.match(filename)\n",
        "            if m:\n",
        "                second, first = map(int, m.groups())\n",
        "                return (second, first)\n",
        "            return (float('inf'), float('inf'))\n",
        "\n",
        "        sorted_files = sorted(files, key=sort_key)\n",
        "\n",
        "        sorted_paths = [os.path.join(wav_src_dir, f) for f in sorted_files]\n",
        "        return sorted_paths\n",
        "\n",
        "    def check_srt_exsis(self, wav_src_dir):\n",
        "        srt_result = []\n",
        "        for w_path in self.get_wav_list_sorted(wav_src_dir):\n",
        "\n",
        "            srt_path = Path(w_path).with_suffix('.srt')\n",
        "\n",
        "            if not srt_path.exists():\n",
        "                srt_result.append(srt_path.stem)\n",
        "\n",
        "        print(f'ä»¥ä¸‹æ–‡ä»¶æ²¡æœ‰srtæ–‡ä»¶, è¯·æ£€æŸ¥è¯­éŸ³æ–‡ä»¶ {srt_result}')\n",
        "\n",
        "    def generate_srt_dir(self, wav_src_dir, wav_regex, over_write=False):\n",
        "        for w_path in self.get_wav_list_sorted(wav_src_dir, wav_regex):\n",
        "\n",
        "            try:\n",
        "                self.generate_srt_file(w_path, over_write)\n",
        "            except Exception as e:\n",
        "                print(f\"å¤„ç†æ–‡ä»¶ {w_path} æ—¶å‘ç”Ÿé”™è¯¯ï¼š{e}\")\n",
        "\n",
        "    def asr_with_target(self, wav_file):\n",
        "        \n",
        "        wav_path = Path(wav_file)\n",
        "        txt_path = wav_path.with_suffix('.txt')\n",
        "        \n",
        "        output_dir = \"/Volumes/sw/datasets_prepare/meiguodegushi_output/\" + wav_path.stem\n",
        "        if os.path.exists(output_dir):\n",
        "\n",
        "            print(f'âš ï¸ output dir exists {output_dir}, nothing will process ...')\n",
        "            return\n",
        "        target = []\n",
        "        with open(str(txt_path), 'r') as f:\n",
        "            target = f.read().splitlines()\n",
        "\n",
        "        res = self.model.generate(\n",
        "            input=wav_file,\n",
        "            cache={},\n",
        "            language=\"auto\",  # \"zn\", \"en\", \"yue\", \"ja\", \"ko\", \"nospeech\"\n",
        "            use_itn=False,\n",
        "            batch_size_s=30,\n",
        "            merge_vad=True,\n",
        "            merge_length_s=20,\n",
        "            output_timestamp=True,\n",
        "        )\n",
        "        output = res[0]\n",
        "        sent_ts = output[\"timestamp_sentence\"]\n",
        "\n",
        "        target_txt = \"\".join(target)\n",
        "        target_txt = self.normalizer.normalize(target_txt)\n",
        "\n",
        "        target_txt = re.sub(self.combined_pattern, \"\", target_txt)\n",
        "        target_txt = target_txt.replace(\"\\n\", \"\")\n",
        "\n",
        "        target_tokens = self.model.kwargs['tokenizer'].text2tokens(target_txt)\n",
        "        aligned_timestamps, status = self.map_asr_to_correct(output[\"words\"], output[\"timestamp\"], target_tokens)\n",
        "        self.check_status(status)\n",
        "        sen_clips = self.split_tokens_by_sentence(sent_ts, aligned_timestamps, target_tokens)\n",
        "        self.export_audio_segments(wav_file, sen_clips, output_dir)\n",
        "\n",
        "        print(f'âœ… fininsh process wav {wav_file}')\n",
        "\n",
        "    def export_audio_segments(self, audio_file, segments, output_dir):\n",
        "        \"\"\"\n",
        "        audio_file: åŸå§‹éŸ³é¢‘è·¯å¾„\n",
        "        segments: [{'text':..., 'start':..., 'end':...}, ...]\n",
        "            start/end å•ä½ï¼šæ¯«ç§’\n",
        "        output_dir: è¾“å‡ºç›®å½•\n",
        "        \"\"\"\n",
        "        if not os.path.exists(output_dir):\n",
        "            os.makedirs(output_dir)\n",
        "\n",
        "        audio = AudioSegment.from_file(audio_file)\n",
        "\n",
        "        for i, seg in enumerate(segments, 1):\n",
        "            start_ms = seg['start']\n",
        "            end_ms = seg['end']\n",
        "            clip = audio[start_ms:end_ms]\n",
        "            # ä¿å­˜ wav\n",
        "            wav_path = os.path.join(output_dir, f\"{i:03d}.wav\")\n",
        "            clip.export(wav_path, format=\"wav\")\n",
        "\n",
        "            # ä¿å­˜å¯¹åº”æ–‡æœ¬\n",
        "            txt_path = os.path.join(output_dir, f\"{i:03d}.txt\")\n",
        "            with open(txt_path, \"w\", encoding=\"utf-8\") as f:\n",
        "                f.write(seg['text'])\n",
        "\n",
        "            # print(f\"å¯¼å‡º: {wav_path}, {txt_path}\")\n",
        "\n",
        "    def merge_short_sentences(self, sentences, min_duration=3000):\n",
        "        \"\"\"\n",
        "        sentences: [{'text':..., 'start':..., 'end':...}, ...]\n",
        "        min_duration: æœ€å°æ—¶é—´é˜ˆå€¼ï¼Œå•ä½ä¸ start/end ä¸€è‡´ï¼ˆç¤ºä¾‹ä¸­ä¸ºæ¯«ç§’ï¼‰\n",
        "        \"\"\"\n",
        "        if not sentences:\n",
        "            return []\n",
        "\n",
        "        merged = [sentences[0]]\n",
        "\n",
        "        for s in sentences[1:]:\n",
        "            duration = s['end'] - s['start']\n",
        "            if duration < min_duration:\n",
        "                # åˆå¹¶åˆ°ä¸Šä¸€æ¡\n",
        "                prev = merged[-1]\n",
        "                prev['text'] += s['text']\n",
        "                prev['end'] = s['end']\n",
        "            else:\n",
        "                merged.append(s)\n",
        "\n",
        "        return merged\n",
        "\n",
        "    def merge_sent_timestamps(self, sent_ts):\n",
        "        \"\"\"å°†æ¯å¥ä¸­ token çš„æ—¶é—´èŒƒå›´åˆå¹¶ä¸º (start, end)\"\"\"\n",
        "        if len(sent_ts) % 2 != 0:\n",
        "            raise Exception('sent ts count not match with start and end timestamp')\n",
        "        merged = []\n",
        "        for i in range(0, len(sent_ts), 2):\n",
        "            pair = sent_ts[i:i+2]  # å–ä¸¤å…ƒç´ \n",
        "            start = pair[0][0]\n",
        "            end = pair[-1][1]\n",
        "            merged.append((start, end))\n",
        "        return merged\n",
        "\n",
        "    def split_tokens_by_sentence(self, sent_ts, aligned_timestamps, target_tokens):\n",
        "        assert len(aligned_timestamps) == len(target_tokens), \"æ—¶é—´æˆ³ä¸tokenæ•°é‡ä¸ä¸€è‡´\"\n",
        "        results = []\n",
        "        idx = 0\n",
        "        n = len(target_tokens)\n",
        "        for sent_start, sent_end in sent_ts:\n",
        "            sent_tokens = []\n",
        "            # éå† tokenï¼Œç›´åˆ° token èµ·ç‚¹è¶…è¿‡å¥å­ç»“æŸ\n",
        "            while idx < n:\n",
        "                token_start, token_end = aligned_timestamps[idx]\n",
        "                if token_start is not None and token_end is not None:\n",
        "                    # token å®Œå…¨åœ¨å¥å­åŒºé—´å†…\n",
        "                    if token_start >= sent_start and token_end <= sent_end:\n",
        "                        sent_tokens.append(target_tokens[idx])\n",
        "                        idx += 1\n",
        "                    # token è¶…å‡ºå½“å‰å¥å­åŒºé—´ï¼Œè¯´æ˜å½“å‰å¥å­ç»“æŸ\n",
        "                    elif token_start >= sent_end or token_end <= sent_start:\n",
        "                        break\n",
        "                else:\n",
        "                    sent_tokens.append(target_tokens[idx])\n",
        "                    idx += 1\n",
        "\n",
        "            if sent_tokens:\n",
        "                sentence = \"\".join(sent_tokens)\n",
        "                results.append({\n",
        "                    \"text\": sentence,\n",
        "                    \"start\": sent_start,\n",
        "                    \"end\": sent_end\n",
        "                })\n",
        "\n",
        "        return results\n",
        "\n",
        "    def check_status(self, status):\n",
        "        num_tokens = len(status)\n",
        "        num_mismatch = status.count(False)\n",
        "        mismatch_ratio = num_mismatch / num_tokens\n",
        "\n",
        "        if mismatch_ratio > 0.3:\n",
        "            print(f\"âŒâŒ æ³¨æ„, ä¸åŒ¹é…ç‡è¿‡é«˜.  ä¸åŒ¹é… token({num_mismatch}/{num_tokens}) å æ¯”: {mismatch_ratio:.2%}\")\n",
        "            raise Exception()\n",
        "        if mismatch_ratio > 0.15:\n",
        "            print(f\"âš ï¸âŒ æ³¨æ„, ä¸åŒ¹é…ç‡è¿‡é«˜.  ä¸åŒ¹é… token({num_mismatch}/{num_tokens}) å æ¯”: {mismatch_ratio:.2%}\")\n",
        "        else:\n",
        "            print(f\"âš ï¸ ä¸åŒ¹é… token({num_mismatch}/{num_tokens}) å æ¯”: {mismatch_ratio:.2%}\")\n",
        "\n",
        "    def create_clip_with_asr(self, audio_dir):\n",
        "        audio_files = sorted(os.listdir(audio_dir))\n",
        "        for _a_f in audio_files:\n",
        "\n",
        "            if _a_f.endswith('.wav'):\n",
        "                \n",
        "                _audio_file = os.path.join(audio_dir, _a_f)\n",
        "\n",
        "                res_dir =Path(_audio_file).with_suffix(\"\")\n",
        "                res_dir.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "                res = self.model.generate(\n",
        "                    input=_audio_file,\n",
        "                    cache={},\n",
        "                    language=\"auto\",  # \"zn\", \"en\", \"yue\", \"ja\", \"ko\", \"nospeech\"\n",
        "                    use_itn=False,\n",
        "                    batch_size_s=30,\n",
        "                    merge_vad=True,\n",
        "                    merge_length_s=20,\n",
        "                    output_timestamp=True,\n",
        "                )\n",
        "                output = res[0]\n",
        "\n",
        "                audio = AudioSegment.from_file(_audio_file)\n",
        "                sent_timestamps = output['timestamp_sentence']\n",
        "                words = output['words']\n",
        "                words_ts = output['timestamp']\n",
        "\n",
        "                for _i, sent_ts in enumerate(sent_timestamps):\n",
        "                    _start_ts = sent_ts[0]\n",
        "                    _end_ts = sent_ts[1]\n",
        "                    clip = audio[_start_ts: _end_ts]\n",
        "\n",
        "                    _clip_txt = []\n",
        "                    for w, (w_s_ts, w_e_ts) in zip(words, words_ts):\n",
        "                        if w_s_ts >= _start_ts and w_e_ts <= _end_ts:\n",
        "                            _clip_txt.append(w)\n",
        "                        if w_s_ts > _end_ts:\n",
        "                            break\n",
        "                    clip_txt = \"\".join(_clip_txt)\n",
        "\n",
        "                    clip_path = res_dir / f\"{_i:03d}.txt\"\n",
        "                    clip_path.write_text(clip_txt, encoding=\"utf-8\")\n",
        "\n",
        "                    wav_path = os.path.join(res_dir, f\"{_i:03d}.wav\")\n",
        "                    clip.export(wav_path, format=\"wav\")\n",
        "\n",
        "                print(f'âœ… âœ… âœ…  æ–‡ä»¶{_a_f}å¤„ç†å®Œæˆ')\n",
        "\n",
        "env = \"local\" # colab local\n",
        "if env == \"colab\":\n",
        "    cfa = CtcForcdAlign(\n",
        "        # model_dir = \"/Volumes/sw/pretrained_models/SenseVoiceSmall\",\n",
        "        model_dir = \"iic/SenseVoiceSmall\",\n",
        "        device = \"cuda\"\n",
        "    )\n",
        "\n",
        "    book_name = \"tianchaoyaoyuan2\"\n",
        "    cfa.generate_srt_dir(f\"/content/drive/MyDrive/{book_name}\", fr\"{book_name}-(\\d+)_(\\d+)\\.wav\")\n",
        "elif env == 'local':\n",
        "    cfa = CtcForcdAlign(\n",
        "        model_dir = \"/Volumes/sw/pretrained_models/SenseVoiceSmall\",\n",
        "        device = \"mps\"\n",
        "    )\n",
        "    book_name = \"zhipeiyudikang\"\n",
        "    cfa.generate_srt_dir(f\"/Volumes/sw/tts_result/{book_name}\", fr\"{book_name}-(\\d+)_(\\d+)\\.wav\")\n",
        "\n",
        "    cfa.check_srt_exsis(f\"/Volumes/sw/tts_result/{book_name}\")\n",
        "else:\n",
        "    raise Exception('env not support ')\n",
        "\n",
        "# cfa.generate_srt_dir('/Volumes/sw/MyDrive/zhengzhi1/output', r\"zhengzhi1-(\\d+)_(\\d+)\\.wav\", True)\n",
        "# cfa.generate_srt_file(\"/Users/larry/github.com/tardigrade-dot/SenseVoice/data-forcedaligner/data.wav\", True)\n",
        "\n",
        "# wav_dir = \"/Volumes/sw/datasets_prepare/zhongdong\"\n",
        "# for wav_file in os.listdir(wav_dir):\n",
        "#     if wav_file.endswith('.wav'):\n",
        "#         wav_path = os.path.join(wav_dir, wav_file)\n",
        "#         cfa.asr_with_target(wav_path)\n",
        "\n",
        "# cfa.asr_with_target(\"/Volumes/sw/datasets_prepare/meiguodegushi/çœŸäººæœ—è¯»æœ‰å£°ä¹¦ã€Šç¾å›½çš„æ•…äº‹ã€‹ä»1517å®—æ•™æ”¹é©åˆ°ç¾å›½å»ºå›½400å¤šå¹´çš„é£é£é›¨é›¨ p05 05.ç¾æ´²å¤§é™†çš„ä¸»äºº.mp3\")\n",
        "# cfa.generate_srt_file(\"/Volumes/sw/MyDrive/zhengzhi1/output/zhengzhi1-1_3.wav\", True)\n",
        "\n",
        "# cfa.create_clip_with_asr(\"/Volumes/sw/datasets_prepare/qiangpao\")\n",
        "\n",
        "# cfa.generate_srt_dir(\"/Users/larry/Documents/epub/quanliyuwuzhi\", r\"quanliyuwuzhi-(\\d+)_(\\d+)\\.wav\",)\n",
        "\n",
        "# cfa.generate_srt_dir(\"/Users/larry/Documents/epub/fubaiyufanfu\", r\"fubaiyufanfu-(\\d+)_(\\d+)\\.wav\")\n",
        "\n",
        "# cfa.generate_srt_file(\"/Users/larry/github.com/tardigrade-dot/colab-script2/data_src/zhipei-0_0.wav\")\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "authorship_tag": "ABX9TyM85fjLitmu3zNQc7mAAcZY",
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}

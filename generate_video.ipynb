{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyM85fjLitmu3zNQc7mAAcZY",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tardigrade-dot/colab-script/blob/main/generate_video.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!which python"
      ],
      "metadata": {
        "id": "UZvIYOzsQ3XG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!echo $HOSTNAME"
      ],
      "metadata": {
        "id": "9fDFsCdxR-dB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "Is1MrBMf0c6L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "å®‰è£…sensevoiceç¯å¢ƒ"
      ],
      "metadata": {
        "id": "gzKAg107LnW7"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OjP432I2KYA5"
      },
      "outputs": [],
      "source": [
        "!pip install -r https://raw.githubusercontent.com/FunAudioLLM/SenseVoice/refs/heads/main/requirements.txt"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install wetext"
      ],
      "metadata": {
        "id": "_iWFkR2HG79J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# sv311 å®‰è£…SenseVoiceç¯å¢ƒ: https://github.com/FunAudioLLM/SenseVoice\n",
        "\n",
        "import re\n",
        "import os\n",
        "from pathlib import Path\n",
        "import string\n",
        "from funasr import AutoModel\n",
        "import difflib\n",
        "from pydub import AudioSegment\n",
        "# from zh_normalization import TextNormalizer\n",
        "from wetext import Normalizer\n",
        "\n",
        "class CtcForcdAlign:\n",
        "    def __init__(self, model_dir, device) -> None:\n",
        "\n",
        "        self.MIN_CHARS_PER_LINE = 10\n",
        "        self.model = AutoModel(\n",
        "            model=model_dir,\n",
        "            vad_model=\"fsmn-vad\",\n",
        "            vad_kwargs={\"max_single_segment_time\": 30_000},\n",
        "            device=device,\n",
        "            disable_update=True,\n",
        "            trust_remote_code=True,\n",
        "            # remote_code=\"./extro/model.py\",\n",
        "            # remote_code=\"funasr.models.sense_voice.model\",\n",
        "        )\n",
        "\n",
        "        self.normalizer = Normalizer(lang=\"zh\", operator=\"tn\", remove_erhua=True, traditional_to_simple=True)\n",
        "        chinese_pattern = r\"ï¼ˆ.*?ï¼‰\"\n",
        "        english_pattern = r\"\\([^)]*?\\)\"\n",
        "\n",
        "        self.combined_pattern = f\"{chinese_pattern}|{english_pattern}\"\n",
        "        self.PUNCTUATION_CHARS = set(string.punctuation) | set(',.?ï¼Œã€‚ï¼ï¼Ÿï¼›ï¼šã€â€œâ€â€˜â€™ã€Šã€‹ã€ã€‘ï¼ˆï¼‰')\n",
        "        self.PUNCT_REGEX = re.compile(r'[.,:;!?ï¼Œã€‚ã€ï¼›ï¼šï¼Ÿï¼â€œâ€˜â€â€™ï¼ˆï¼‰ã€Šã€‹ã€ã€‘\\s-]')\n",
        "\n",
        "    def is_punctuation(self, token):\n",
        "        return token in self.PUNCTUATION_CHARS\n",
        "\n",
        "    def map_opcodes_to_raw(self, clean_opcodes, asr_timestamps, correct_tokens_raw):\n",
        "        aligned_timestamps = []\n",
        "        status = []\n",
        "\n",
        "        j_raw_ptr = 0\n",
        "\n",
        "        for tag, i1, i2, j1, j2 in clean_opcodes:\n",
        "\n",
        "            while j_raw_ptr < len(correct_tokens_raw) and self.PUNCT_REGEX.match(correct_tokens_raw[j_raw_ptr]):\n",
        "                aligned_timestamps.append((None, None))\n",
        "                j_raw_ptr += 1\n",
        "\n",
        "            asr_chars_consumed = i2 - i1\n",
        "            if tag == \"equal\":\n",
        "                for k in range(j2 - j1): # éå†åŒ¹é…çš„æ±‰å­—\n",
        "                    aligned_timestamps.append(asr_timestamps[i1 + k])\n",
        "                    status.append(True)\n",
        "                    j_raw_ptr += 1 # åŸå§‹æŒ‡é’ˆç§»åŠ¨ä¸€ä¸ªæ±‰å­—\n",
        "                    while j_raw_ptr < len(correct_tokens_raw) and self.PUNCT_REGEX.match(correct_tokens_raw[j_raw_ptr]):\n",
        "                        aligned_timestamps.append((None, None))\n",
        "                        j_raw_ptr += 1\n",
        "            elif tag == \"replace\" or tag == \"insert\":\n",
        "                for k in range(j2 - j1): # éå†å·®å¼‚çš„æ±‰å­—\n",
        "                    if asr_chars_consumed > 0:\n",
        "                        idx = i1 + k % asr_chars_consumed\n",
        "                        aligned_timestamps.append(asr_timestamps[idx])\n",
        "                    else: # çº¯ç²¹çš„æ’å…¥ (tag='insert')\n",
        "                        aligned_timestamps.append((None, None))\n",
        "                    status.append(False)\n",
        "                    j_raw_ptr += 1 # åŸå§‹æŒ‡é’ˆç§»åŠ¨ä¸€ä¸ªæ±‰å­—\n",
        "                    while j_raw_ptr < len(correct_tokens_raw) and self.PUNCT_REGEX.match(correct_tokens_raw[j_raw_ptr]):\n",
        "                        aligned_timestamps.append((None, None))\n",
        "                        j_raw_ptr += 1\n",
        "            elif tag == \"delete\":\n",
        "                continue\n",
        "\n",
        "        while j_raw_ptr < len(correct_tokens_raw) and self.PUNCT_REGEX.match(correct_tokens_raw[j_raw_ptr]):\n",
        "            aligned_timestamps.append((None, None))\n",
        "            j_raw_ptr += 1\n",
        "        if len(aligned_timestamps) == len(correct_tokens_raw):\n",
        "            return aligned_timestamps, status\n",
        "        else:\n",
        "            print(f\"ğŸš¨ è­¦å‘Š: æœ€ç»ˆé•¿åº¦ä¸åŒ¹é…. Raw: {len(correct_tokens_raw)}, Aligned: {len(aligned_timestamps)}\")\n",
        "            return aligned_timestamps, status\n",
        "\n",
        "    def map_asr_to_correct(self, asr_tokens, asr_timestamps, correct_tokens):\n",
        "\n",
        "        punctuation_regex = r'[.,:;!?ï¼Œã€‚ã€ï¼›ï¼šï¼Ÿï¼â€œâ€˜â€â€™ï¼ˆï¼‰ã€Šã€‹ã€ã€‘\\s-]'\n",
        "        clean_correct_tokens = re.sub(punctuation_regex, '', correct_tokens)\n",
        "        matcher_clean = difflib.SequenceMatcher(None, asr_tokens, clean_correct_tokens)\n",
        "        clean_opcodes = matcher_clean.get_opcodes()\n",
        "\n",
        "        return self.map_opcodes_to_raw(clean_opcodes, asr_timestamps, correct_tokens)\n",
        "\n",
        "    #old version\n",
        "    def map_asr_to_correct_oldversion(self, asr_tokens, asr_timestamps, correct_tokens):\n",
        "        \"\"\"\n",
        "        å°†ASR tokenæ—¶é—´æˆ³æ˜ å°„åˆ°æ­£ç¡®æ–‡æœ¬ token\n",
        "        è¿”å›ï¼š\n",
        "            aligned_timestamps: å¯¹é½åçš„æ­£ç¡®æ–‡æœ¬æ—¶é—´æˆ³åˆ—è¡¨\n",
        "            status: æ¯ä¸ª token æ˜¯å¦åŒ¹é…\n",
        "        \"\"\"\n",
        "        aligned_timestamps = []\n",
        "        status = []\n",
        "\n",
        "        # asr_tokens = \"\".join(asr_tokens)\n",
        "        # ä½¿ç”¨ difflib å¯¹é½ ASR ä¸æ­£ç¡®æ–‡æœ¬\n",
        "        matcher = difflib.SequenceMatcher(self.is_punctuation, asr_tokens, correct_tokens)\n",
        "        for tag, i1, i2, j1, j2 in matcher.get_opcodes():\n",
        "            if tag == \"equal\":\n",
        "                # token åŒ¹é… â†’ ç›´æ¥ç»§æ‰¿æ—¶é—´æˆ³\n",
        "                for k in range(j2 - j1):\n",
        "                    aligned_timestamps.append(asr_timestamps[i1 + k])\n",
        "                    status.append(True)\n",
        "            elif tag == \"replace\":\n",
        "                # token æ›¿æ¢ â†’ å°è¯•å¹³å‡åˆ†é…æ—¶é—´æˆ³\n",
        "                # å¯ä»¥é€‰æ‹©æ ‡è®°ä¸ºä¸åŒ¹é…\n",
        "                for k in range(j2 - j1):\n",
        "                    if (i2 - i1) > 0:\n",
        "                        idx = i1 + k % (i2 - i1)\n",
        "                        aligned_timestamps.append(asr_timestamps[idx])\n",
        "                    else:\n",
        "                        # ASR æ²¡æœ‰å¯¹åº” token â†’ å¡«å…… None\n",
        "                        aligned_timestamps.append((None, None))\n",
        "                    status.append(False)\n",
        "            elif tag == \"insert\":\n",
        "                # æ­£ç¡®æ–‡æœ¬ä¸­æ–°å¢ token â†’ æ— å¯¹åº” ASR token\n",
        "                for _ in range(j2 - j1):\n",
        "                    aligned_timestamps.append((None, None))\n",
        "                    status.append(False)\n",
        "            elif tag == \"delete\":\n",
        "                # ASR ä¸­å¤šä½™ token â†’ å¿½ç•¥\n",
        "                continue\n",
        "\n",
        "        return aligned_timestamps, status\n",
        "\n",
        "    def is_valid_time(self, t):\n",
        "        return isinstance(t, (int, float)) and t >= 0\n",
        "\n",
        "    def get_valid_start_end(self, words):\n",
        "        start_time, end_time = None, None\n",
        "\n",
        "        for w in words:\n",
        "            t = w.get('start')\n",
        "            if self.is_valid_time(t):\n",
        "                start_time = t\n",
        "                break\n",
        "\n",
        "        for w in reversed(words):\n",
        "            t = w.get('end')\n",
        "            if self.is_valid_time(t):\n",
        "                end_time = t\n",
        "                break\n",
        "\n",
        "        return start_time, end_time\n",
        "\n",
        "    def ms_to_srt_time_format(self, ms):\n",
        "        # ç¡®ä¿è¾“å…¥æ˜¯æ•´æ•°æˆ–å¯ä»¥è½¬æ¢ä¸ºæ•´æ•°\n",
        "        ms = int(ms)\n",
        "        # è®¡ç®—å°æ—¶ã€åˆ†é’Ÿã€ç§’å’Œæ¯«ç§’\n",
        "        hours = ms // 3600000\n",
        "        minutes = (ms % 3600000) // 60000\n",
        "        seconds = (ms % 60000) // 1000\n",
        "        milliseconds = ms % 1000\n",
        "\n",
        "        # ä½¿ç”¨ f-string æ ¼å¼åŒ–è¾“å‡ºï¼Œç¡®ä¿æ¯ä¸ªéƒ¨åˆ†éƒ½æœ‰å›ºå®šçš„ä½æ•°\n",
        "        return f\"{hours:02d}:{minutes:02d}:{seconds:02d},{milliseconds:03d}\"\n",
        "\n",
        "    def generate_srt_from_words_and_timestamps(self, words, timestamps):\n",
        "        if not words or not timestamps or len(words) != len(timestamps):\n",
        "            print(f\"words length[{len(words)}] not equal to timestamps length[{len(timestamps)}]\")\n",
        "            raise Exception('process error')\n",
        "\n",
        "        srt_content = \"\"\n",
        "        subtitle_index = 1\n",
        "        sentence_delimiters = ['ã€‚', 'ï¼Ÿ', 'ï¼', '.', '?', '!', 'â€¦']\n",
        "\n",
        "        current_subtitle_words = []\n",
        "        end_time = 0\n",
        "\n",
        "        # å†…éƒ¨å‡½æ•°ï¼šè´Ÿè´£åˆ¤æ–­æ˜¯å¦æ»¡è¶³é•¿åº¦è¦æ±‚å¹¶è¾“å‡ºå­—å¹•\n",
        "        def _write_subtitle(words_to_write, pre_end_time):\n",
        "            nonlocal srt_content, subtitle_index\n",
        "\n",
        "            if not words_to_write:\n",
        "                return None\n",
        "\n",
        "            # start_time = words_to_write[0]['start']\n",
        "            # end_time = words_to_write[-1]['end']\n",
        "            start_time, end_time = self.get_valid_start_end(words_to_write)\n",
        "            if pre_end_time and pre_end_time != 0 and start_time < pre_end_time:\n",
        "                start_time = pre_end_time\n",
        "\n",
        "            # å°†å•è¯åˆ—è¡¨ç»„åˆæˆä¸€ä¸ªå®Œæ•´çš„å¥å­\n",
        "            sentence_text = \"\".join([w['word'] for w in words_to_write])\n",
        "\n",
        "            srt_content += str(subtitle_index) + \"\\n\"\n",
        "            srt_content += f\"{self.ms_to_srt_time_format(start_time)} --> {self.ms_to_srt_time_format(end_time)}\\n\"\n",
        "            srt_content += sentence_text + \"\\n\\n\"\n",
        "            subtitle_index += 1\n",
        "            return end_time\n",
        "\n",
        "        for i in range(len(words)):\n",
        "            word = words[i]\n",
        "            timestamp = timestamps[i]\n",
        "\n",
        "            current_subtitle_words.append({'word': word, 'start': timestamp[0], 'end': timestamp[1]})\n",
        "\n",
        "            is_sentence_end = word in sentence_delimiters\n",
        "            if is_sentence_end:\n",
        "                current_text = \"\".join([w['word'] for w in current_subtitle_words])\n",
        "                current_length = len(current_text)\n",
        "                if current_length >= self.MIN_CHARS_PER_LINE:\n",
        "                    end_time = _write_subtitle(current_subtitle_words, end_time)\n",
        "                    current_subtitle_words = [] # æ¸…ç©ºç´¯è®¡åˆ—è¡¨\n",
        "        if current_subtitle_words:\n",
        "            all_none = all(\n",
        "                item['start'] is None and item['end'] is None\n",
        "                for item in current_subtitle_words\n",
        "            )\n",
        "            if not all_none:\n",
        "                _write_subtitle(current_subtitle_words, end_time)\n",
        "\n",
        "        return srt_content\n",
        "\n",
        "    def generate_srt_file(self, wav_file, over_write=False):\n",
        "\n",
        "        wav_path = Path(wav_file)\n",
        "\n",
        "        txt_path = wav_path.with_suffix('.txt')\n",
        "        srt_path = wav_path.with_suffix('.srt')\n",
        "\n",
        "        txt_file = str(txt_path)\n",
        "        srt_file = str(srt_path)\n",
        "\n",
        "        print(f'\\nwav [{wav_file}], \\ntxt [{txt_file}], \\nsrt [{srt_file}]')\n",
        "\n",
        "        if not wav_path.exists():\n",
        "            raise Exception(f'wav file[{wav_file}] not exists ')\n",
        "        if not txt_path.exists():\n",
        "            raise Exception(f'txt file[{txt_file}] not exists ')\n",
        "        if srt_path.exists() and not over_write:\n",
        "            print(f'srt file[{srt_file}] exists, just return ')\n",
        "            return\n",
        "\n",
        "        with open(txt_file, 'r') as f:\n",
        "            target_txt = \"\".join(f.readlines())\n",
        "\n",
        "        res = self.model.generate(\n",
        "                input=wav_file,\n",
        "                cache={},\n",
        "                language=\"auto\",  # \"zn\", \"en\", \"yue\", \"ja\", \"ko\", \"nospeech\"\n",
        "                use_itn=False,\n",
        "                batch_size_s=30,\n",
        "                merge_vad=True,\n",
        "                merge_length_s=20,\n",
        "                output_timestamp=True,\n",
        "            )\n",
        "        output = res[0]\n",
        "\n",
        "        target_txt = re.sub(self.combined_pattern, \"\", target_txt)\n",
        "        target_txt = target_txt.replace(\"\\n\", \" \")\n",
        "        target_txt = self.normalizer.normalize(target_txt)\n",
        "\n",
        "        aligned_timestamps, status = self.map_asr_to_correct(output[\"words\"], output[\"timestamp\"], target_txt)\n",
        "\n",
        "        num_tokens = len(status)\n",
        "        num_mismatch = status.count(False)\n",
        "        mismatch_ratio = num_mismatch / num_tokens\n",
        "\n",
        "        if mismatch_ratio > 0.05:\n",
        "            print(f\"âš ï¸âŒ æ³¨æ„, ä¸åŒ¹é…ç‡è¿‡é«˜.  ä¸åŒ¹é… token({num_mismatch}/{num_tokens}) å æ¯”: {mismatch_ratio:.2%}\")\n",
        "        else:\n",
        "            print(f\"âš ï¸ ä¸åŒ¹é… token({num_mismatch}/{num_tokens}) å æ¯”: {mismatch_ratio:.2%}\")\n",
        "\n",
        "        srt_result = self.generate_srt_from_words_and_timestamps(target_txt, aligned_timestamps)\n",
        "\n",
        "        with open(srt_file, 'w') as f:\n",
        "            f.write(srt_result)\n",
        "\n",
        "        print(f\"å­—å¹•å·²ç”Ÿæˆ, ä¿å­˜åœ¨:{srt_file}\")\n",
        "\n",
        "    def get_wav_list_sorted(self, wav_src_dir, wav_regex):\n",
        "        pattern = re.compile(wav_regex)\n",
        "\n",
        "        files = [\n",
        "            f for f in os.listdir(wav_src_dir)\n",
        "            if f.endswith('.wav') and pattern.match(f)\n",
        "        ]\n",
        "\n",
        "        def sort_key(filename):\n",
        "            m = pattern.match(filename)\n",
        "            if m:\n",
        "                second, first = map(int, m.groups())\n",
        "                return (second, first)\n",
        "            return (float('inf'), float('inf'))\n",
        "\n",
        "        sorted_files = sorted(files, key=sort_key)\n",
        "\n",
        "        sorted_paths = [os.path.join(wav_src_dir, f) for f in sorted_files]\n",
        "        return sorted_paths\n",
        "\n",
        "    def generate_srt_dir(self, wav_src_dir, wav_regex, over_write=False):\n",
        "        for w_path in self.get_wav_list_sorted(wav_src_dir, wav_regex):\n",
        "            self.generate_srt_file(w_path, over_write)\n",
        "\n",
        "    def asr_with_target(self, wav_file):\n",
        "\n",
        "        wav_path = Path(wav_file)\n",
        "        txt_path = wav_path.with_suffix('.txt')\n",
        "\n",
        "        output_dir = \"/Volumes/sw/datasets_prepare/meiguodegushi_output/\" + wav_path.stem\n",
        "        if os.path.exists(output_dir):\n",
        "\n",
        "            print(f'âš ï¸ output dir exists {output_dir}, nothing will process ...')\n",
        "            return\n",
        "        target = []\n",
        "        with open(str(txt_path), 'r') as f:\n",
        "            target = f.read().splitlines()\n",
        "\n",
        "        res = self.model.generate(\n",
        "            input=wav_file,\n",
        "            cache={},\n",
        "            language=\"auto\",  # \"zn\", \"en\", \"yue\", \"ja\", \"ko\", \"nospeech\"\n",
        "            use_itn=False,\n",
        "            batch_size_s=30,\n",
        "            merge_vad=True,\n",
        "            merge_length_s=20,\n",
        "            output_timestamp=True,\n",
        "        )\n",
        "        output = res[0]\n",
        "        sent_ts = output[\"timestamp_sentence\"]\n",
        "\n",
        "        target_txt = \"\".join(target)\n",
        "        target_txt = self.normalizer.normalize(target_txt)\n",
        "\n",
        "        target_txt = re.sub(self.combined_pattern, \"\", target_txt)\n",
        "        target_txt = target_txt.replace(\"\\n\", \"\")\n",
        "\n",
        "        target_tokens = self.model.kwargs['tokenizer'].text2tokens(target_txt)\n",
        "        aligned_timestamps, status = self.map_asr_to_correct(output[\"words\"], output[\"timestamp\"], target_tokens)\n",
        "        self.check_status(status)\n",
        "        sen_clips = self.split_tokens_by_sentence(sent_ts, aligned_timestamps, target_tokens)\n",
        "        self.export_audio_segments(wav_file, sen_clips, output_dir)\n",
        "\n",
        "        print(f'âœ… fininsh process wav {wav_file}')\n",
        "\n",
        "    def export_audio_segments(self, audio_file, segments, output_dir):\n",
        "        \"\"\"\n",
        "        audio_file: åŸå§‹éŸ³é¢‘è·¯å¾„\n",
        "        segments: [{'text':..., 'start':..., 'end':...}, ...]\n",
        "            start/end å•ä½ï¼šæ¯«ç§’\n",
        "        output_dir: è¾“å‡ºç›®å½•\n",
        "        \"\"\"\n",
        "        if not os.path.exists(output_dir):\n",
        "            os.makedirs(output_dir)\n",
        "\n",
        "        audio = AudioSegment.from_file(audio_file)\n",
        "\n",
        "        for i, seg in enumerate(segments, 1):\n",
        "            start_ms = seg['start']\n",
        "            end_ms = seg['end']\n",
        "            clip = audio[start_ms:end_ms]\n",
        "            # ä¿å­˜ wav\n",
        "            wav_path = os.path.join(output_dir, f\"{i:03d}.wav\")\n",
        "            clip.export(wav_path, format=\"wav\")\n",
        "\n",
        "            # ä¿å­˜å¯¹åº”æ–‡æœ¬\n",
        "            txt_path = os.path.join(output_dir, f\"{i:03d}.txt\")\n",
        "            with open(txt_path, \"w\", encoding=\"utf-8\") as f:\n",
        "                f.write(seg['text'])\n",
        "\n",
        "            # print(f\"å¯¼å‡º: {wav_path}, {txt_path}\")\n",
        "\n",
        "    def merge_short_sentences(self, sentences, min_duration=3000):\n",
        "        \"\"\"\n",
        "        sentences: [{'text':..., 'start':..., 'end':...}, ...]\n",
        "        min_duration: æœ€å°æ—¶é—´é˜ˆå€¼ï¼Œå•ä½ä¸ start/end ä¸€è‡´ï¼ˆç¤ºä¾‹ä¸­ä¸ºæ¯«ç§’ï¼‰\n",
        "        \"\"\"\n",
        "        if not sentences:\n",
        "            return []\n",
        "\n",
        "        merged = [sentences[0]]\n",
        "\n",
        "        for s in sentences[1:]:\n",
        "            duration = s['end'] - s['start']\n",
        "            if duration < min_duration:\n",
        "                # åˆå¹¶åˆ°ä¸Šä¸€æ¡\n",
        "                prev = merged[-1]\n",
        "                prev['text'] += s['text']\n",
        "                prev['end'] = s['end']\n",
        "            else:\n",
        "                merged.append(s)\n",
        "\n",
        "        return merged\n",
        "\n",
        "    def merge_sent_timestamps(self, sent_ts):\n",
        "        \"\"\"å°†æ¯å¥ä¸­ token çš„æ—¶é—´èŒƒå›´åˆå¹¶ä¸º (start, end)\"\"\"\n",
        "        if len(sent_ts) % 2 != 0:\n",
        "            raise Exception('sent ts count not match with start and end timestamp')\n",
        "        merged = []\n",
        "        for i in range(0, len(sent_ts), 2):\n",
        "            pair = sent_ts[i:i+2]  # å–ä¸¤å…ƒç´ \n",
        "            start = pair[0][0]\n",
        "            end = pair[-1][1]\n",
        "            merged.append((start, end))\n",
        "        return merged\n",
        "\n",
        "    def split_tokens_by_sentence(self, sent_ts, aligned_timestamps, target_tokens):\n",
        "        assert len(aligned_timestamps) == len(target_tokens), \"æ—¶é—´æˆ³ä¸tokenæ•°é‡ä¸ä¸€è‡´\"\n",
        "        results = []\n",
        "        idx = 0\n",
        "        n = len(target_tokens)\n",
        "        for sent_start, sent_end in sent_ts:\n",
        "            sent_tokens = []\n",
        "            # éå† tokenï¼Œç›´åˆ° token èµ·ç‚¹è¶…è¿‡å¥å­ç»“æŸ\n",
        "            while idx < n:\n",
        "                token_start, token_end = aligned_timestamps[idx]\n",
        "                if token_start is not None and token_end is not None:\n",
        "                    # token å®Œå…¨åœ¨å¥å­åŒºé—´å†…\n",
        "                    if token_start >= sent_start and token_end <= sent_end:\n",
        "                        sent_tokens.append(target_tokens[idx])\n",
        "                        idx += 1\n",
        "                    # token è¶…å‡ºå½“å‰å¥å­åŒºé—´ï¼Œè¯´æ˜å½“å‰å¥å­ç»“æŸ\n",
        "                    elif token_start >= sent_end or token_end <= sent_start:\n",
        "                        break\n",
        "                else:\n",
        "                    sent_tokens.append(target_tokens[idx])\n",
        "                    idx += 1\n",
        "\n",
        "            if sent_tokens:\n",
        "                sentence = \"\".join(sent_tokens)\n",
        "                results.append({\n",
        "                    \"text\": sentence,\n",
        "                    \"start\": sent_start,\n",
        "                    \"end\": sent_end\n",
        "                })\n",
        "\n",
        "        return results\n",
        "\n",
        "    def check_status(self, status):\n",
        "        num_tokens = len(status)\n",
        "        num_mismatch = status.count(False)\n",
        "        mismatch_ratio = num_mismatch / num_tokens\n",
        "\n",
        "        if mismatch_ratio > 0.3:\n",
        "            print(f\"âŒâŒ æ³¨æ„, ä¸åŒ¹é…ç‡è¿‡é«˜.  ä¸åŒ¹é… token({num_mismatch}/{num_tokens}) å æ¯”: {mismatch_ratio:.2%}\")\n",
        "            raise Exception()\n",
        "        if mismatch_ratio > 0.15:\n",
        "            print(f\"âš ï¸âŒ æ³¨æ„, ä¸åŒ¹é…ç‡è¿‡é«˜.  ä¸åŒ¹é… token({num_mismatch}/{num_tokens}) å æ¯”: {mismatch_ratio:.2%}\")\n",
        "        else:\n",
        "            print(f\"âš ï¸ ä¸åŒ¹é… token({num_mismatch}/{num_tokens}) å æ¯”: {mismatch_ratio:.2%}\")\n",
        "\n",
        "    def create_clip_with_asr(self, audio_dir):\n",
        "        audio_files = sorted(os.listdir(audio_dir))\n",
        "        for _a_f in audio_files:\n",
        "\n",
        "            if _a_f.endswith('.wav'):\n",
        "\n",
        "                _audio_file = os.path.join(audio_dir, _a_f)\n",
        "\n",
        "                res_dir =Path(_audio_file).with_suffix(\"\")\n",
        "                res_dir.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "                res = self.model.generate(\n",
        "                    input=_audio_file,\n",
        "                    cache={},\n",
        "                    language=\"auto\",  # \"zn\", \"en\", \"yue\", \"ja\", \"ko\", \"nospeech\"\n",
        "                    use_itn=False,\n",
        "                    batch_size_s=30,\n",
        "                    merge_vad=True,\n",
        "                    merge_length_s=20,\n",
        "                    output_timestamp=True,\n",
        "                )\n",
        "                output = res[0]\n",
        "\n",
        "                audio = AudioSegment.from_file(_audio_file)\n",
        "                sent_timestamps = output['timestamp_sentence']\n",
        "                words = output['words']\n",
        "                words_ts = output['timestamp']\n",
        "\n",
        "                for _i, sent_ts in enumerate(sent_timestamps):\n",
        "                    _start_ts = sent_ts[0]\n",
        "                    _end_ts = sent_ts[1]\n",
        "                    clip = audio[_start_ts: _end_ts]\n",
        "\n",
        "                    _clip_txt = []\n",
        "                    for w, (w_s_ts, w_e_ts) in zip(words, words_ts):\n",
        "                        if w_s_ts >= _start_ts and w_e_ts <= _end_ts:\n",
        "                            _clip_txt.append(w)\n",
        "                        if w_s_ts > _end_ts:\n",
        "                            break\n",
        "                    clip_txt = \"\".join(_clip_txt)\n",
        "\n",
        "                    clip_path = res_dir / f\"{_i:03d}.txt\"\n",
        "                    clip_path.write_text(clip_txt, encoding=\"utf-8\")\n",
        "\n",
        "                    wav_path = os.path.join(res_dir, f\"{_i:03d}.wav\")\n",
        "                    clip.export(wav_path, format=\"wav\")\n",
        "\n",
        "                print(f'âœ… âœ… âœ…  æ–‡ä»¶{_a_f}å¤„ç†å®Œæˆ')\n",
        "\n",
        "    def check_audio(self, audio_dir):\n",
        "\n",
        "        sub_data_dir_list = sorted(os.listdir(audio_dir))\n",
        "\n",
        "        for _i, _d in enumerate(sub_data_dir_list):\n",
        "            _d2 = os.path.join(audio_dir, _d)\n",
        "            if Path(_d2).is_dir():\n",
        "\n",
        "                for _f in sorted(os.listdir(_d2)):\n",
        "                    if _f.endswith('.wav'):\n",
        "\n",
        "                        _audio_file = os.path.join(_d2, _f)\n",
        "                        txt_file = Path(_audio_file).with_suffix('.txt')\n",
        "                        file_text = Path(txt_file).read_text()\n",
        "\n",
        "                        res = self.model.generate(\n",
        "                            input=_audio_file,\n",
        "                            cache={},\n",
        "                            language=\"auto\",  # \"zn\", \"en\", \"yue\", \"ja\", \"ko\", \"nospeech\"\n",
        "                            use_itn=False,\n",
        "                            batch_size_s=30,\n",
        "                            merge_vad=True,\n",
        "                            merge_length_s=20,\n",
        "                        )\n",
        "                        text = res[0]['text']\n",
        "                        asr_text = re.sub(r\"(?:<\\|[^|>]+\\|>)+\", \"\", text).replace(\" \", \"\")\n",
        "\n",
        "                        file_text = re.sub(r\"[^\\u4e00-\\u9fa5a-zA-Z0-9]\", \"\", file_text).replace(\" \", \"\")\n",
        "\n",
        "                        matcher = difflib.SequenceMatcher(None, asr_text, file_text)\n",
        "                        similarity = matcher.ratio()\n",
        "                        error_rate = 1 - similarity\n",
        "\n",
        "                        print(f\"ç›¸ä¼¼åº¦: {similarity:.4f}, é”™è¯¯ç‡: {error_rate:.4f}\")\n",
        "                        if error_rate < 0.1 and len(file_text) == len(asr_text):\n",
        "                            continue\n",
        "                        if error_rate > 0.09 :\n",
        "                            print(f'âš ï¸ âš ï¸ âš ï¸ {_audio_file}')\n",
        "                            print(f'âš ï¸ âš ï¸ âš ï¸ é”™è¯¯ç‡ {error_rate}')\n",
        "                            print(f'asr_text:{asr_text}')\n",
        "                            print(f'file_text:{file_text}')\n",
        "                            print('')\n",
        "                print(f'âœ… âœ… âœ… [{_i}]å®Œæˆå¤„ç†è·¯å¾„:{_d2}')\n",
        "\n",
        "\n",
        "env = \"colab\" # colab local\n",
        "if env == \"colab\":\n",
        "    cfa = CtcForcdAlign(\n",
        "        # model_dir = \"/Volumes/sw/pretrained_models/SenseVoiceSmall\",\n",
        "        model_dir = \"iic/SenseVoiceSmall\",\n",
        "        device = \"cuda\"\n",
        "    )\n",
        "    cfa.generate_srt_dir(\"/content/drive/MyDrive/tianchaoyaoyuan1\", r\"tianchaoyaoyuan1-(\\d+)_(\\d+)\\.wav\")\n",
        "elif env == 'local':\n",
        "    cfa = CtcForcdAlign(\n",
        "        model_dir = \"/Users/larry/github.com/tardigrade-dot/SenseVoice/models/SenseVoiceSmall\",\n",
        "        device = \"cpu\"\n",
        "    )\n",
        "    cfa.generate_srt_dir(\"/Users/larry/Documents/epub/fubaiyufanfu\", r\"fubaiyufanfu-(\\d+)_(\\d+)\\.wav\")\n",
        "else:\n",
        "    raise Exception('env not support ')\n",
        "# cfa.generate_srt_dir('/Volumes/sw/MyDrive/zhengzhi1/output', r\"zhengzhi1-(\\d+)_(\\d+)\\.wav\", True)\n",
        "# cfa.generate_srt_file(\"/Users/larry/github.com/tardigrade-dot/SenseVoice/data-forcedaligner/data.wav\", True)\n",
        "\n",
        "# wav_dir = \"/Volumes/sw/datasets_prepare/zhongdong\"\n",
        "# for wav_file in os.listdir(wav_dir):\n",
        "#     if wav_file.endswith('.wav'):\n",
        "#         wav_path = os.path.join(wav_dir, wav_file)\n",
        "#         cfa.asr_with_target(wav_path)\n",
        "\n",
        "# cfa.asr_with_target(\"/Volumes/sw/datasets_prepare/meiguodegushi/çœŸäººæœ—è¯»æœ‰å£°ä¹¦ã€Šç¾å›½çš„æ•…äº‹ã€‹ä»1517å®—æ•™æ”¹é©åˆ°ç¾å›½å»ºå›½400å¤šå¹´çš„é£é£é›¨é›¨ p05 05.ç¾æ´²å¤§é™†çš„ä¸»äºº.mp3\")\n",
        "# cfa.generate_srt_file(\"/Volumes/sw/MyDrive/zhengzhi1/output/zhengzhi1-1_3.wav\", True)\n",
        "\n",
        "# cfa.check_audio(\"/Volumes/sw/datasets_prepare/meiguodegushi_output\")\n",
        "\n",
        "# cfa.create_clip_with_asr(\"/Volumes/sw/datasets_prepare/qiangpao\")\n",
        "\n",
        "# cfa.generate_srt_dir(\"/Users/larry/Documents/epub/quanliyuwuzhi\", r\"quanliyuwuzhi-(\\d+)_(\\d+)\\.wav\",)\n",
        "\n",
        "# cfa.generate_srt_dir(\"/content/drive/MyDrive/tianchaoyaoyuan1\", r\"tianchaoyaoyuan1-(\\d+)_(\\d+)\\.wav\")\n",
        "\n",
        "# cfa.generate_srt_file(\"/Users/larry/github.com/tardigrade-dot/colab-script2/data_src/zhipei-0_0.wav\")\n"
      ],
      "metadata": {
        "id": "_6E-XaOWLs2N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "ç”Ÿæˆè§†é¢‘"
      ],
      "metadata": {
        "id": "PlLtino4Nzhn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install moviepy==2.2.1 pysrt tqdm"
      ],
      "metadata": {
        "id": "_Aw196v-0Gyy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!ffmpeg -encoders | grep 'nvenc\\|cuda'"
      ],
      "metadata": {
        "id": "TTXH1DrU1PEh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# torch311\n",
        "# /Users/larry/miniconda3/envs/torch311/bin/python /Users/larry/github.com/tardigrade-dot/colab-script/moviepy_example.py\n",
        "from moviepy import *\n",
        "# from tqdm import tqdm\n",
        "from tqdm.notebook import tqdm\n",
        "import pysrt\n",
        "import os\n",
        "from pathlib import Path\n",
        "import re\n",
        "import subprocess\n",
        "import shlex\n",
        "\n",
        "# ---- å­—ä½“è·¯å¾„ ----\n",
        "FONT_PATH = \"/content/drive/MyDrive/data_src/pingfang-sc-regular.ttf\"\n",
        "\n",
        "# ----------------------------\n",
        "# ç¼–ç å™¨ / CUDA æ£€æµ‹ ä¸ é…ç½®ï¼ˆåªå½±å“ç¼–ç å‚æ•°ï¼‰\n",
        "# ----------------------------\n",
        "# å¯é€‰ï¼š\"auto\" / \"fast\" / \"quality\" / \"cpu\"\n",
        "# \"auto\"ï¼šå¦‚æœæ£€æµ‹åˆ° NVENC åˆ™ç”¨ fast æˆ– quality ä¸­ä¹‹ä¸€ï¼ˆç”± ENCODER_MODE ç»“åˆä¸‹é¢çš„é€‰æ‹©é€»è¾‘å†³å®šï¼‰\n",
        "# \"fast\"ï¼šä½¿ç”¨é€Ÿåº¦ä¼˜å…ˆçš„ NVENC é…ç½®ï¼ˆè‹¥æ—  NVENC å›é€€åˆ° libx264ï¼‰\n",
        "# \"quality\"ï¼šä½¿ç”¨ç”»è´¨ä¼˜å…ˆçš„ NVENC é…ç½®ï¼ˆè‹¥æ—  NVENC å›é€€åˆ° libx264ï¼‰\n",
        "# \"cpu\"ï¼šå¼ºåˆ¶ä½¿ç”¨ libx264ï¼ˆCPUï¼‰\n",
        "ENCODER_MODE = \"cpu\"  # å¯æ”¹ä¸º \"fast\" / \"quality\" / \"cpu\"\n",
        "\n",
        "def detect_nvenc():\n",
        "    \"\"\"\n",
        "    æ£€æŸ¥æœ¬æœº ffmpeg æ˜¯å¦æ”¯æŒ h264_nvenc ç¼–ç å™¨ã€‚\n",
        "    è¿”å› Trueï¼ˆæ”¯æŒï¼‰æˆ– Falseï¼ˆä¸æ”¯æŒæˆ– ffmpeg ä¸å¯ç”¨ï¼‰ã€‚\n",
        "    \"\"\"\n",
        "    try:\n",
        "        # è¿è¡Œ ffmpeg -hide_banner -encoders å¹¶æ£€æŸ¥è¾“å‡º\n",
        "        p = subprocess.run([\"ffmpeg\", \"-hide_banner\", \"-encoders\"], capture_output=True, text=True, timeout=8)\n",
        "        out = p.stdout + p.stderr\n",
        "        return \"h264_nvenc\" in out\n",
        "    except Exception:\n",
        "        return False\n",
        "\n",
        "_NVENC_AVAILABLE = detect_nvenc()\n",
        "\n",
        "def get_encoder_config(mode=ENCODER_MODE):\n",
        "    \"\"\"\n",
        "    è¿”å›ä¸‰å…ƒç»„:\n",
        "      - codec_for_moviepy (string)  e.g. \"h264_nvenc\" or \"libx264\"\n",
        "      - ffmpeg_params_for_moviepy (list)  (ä¼ ç»™ moviepy.write_videofile çš„ ffmpeg_params)\n",
        "      - extra_concat_params (list)  (åœ¨ combine_mp4 subprocess è°ƒç”¨ä¸­æ’å…¥ï¼Œä¾‹: ['-c:v','h264_nvenc','-preset','p4', ...])\n",
        "    ä»…ä¿®æ”¹ç¼–ç ç›¸å…³å‚æ•°ï¼Œå…¶ä»–é€»è¾‘ä¸å˜ã€‚\n",
        "    \"\"\"\n",
        "    # CPU fallback params (libx264)\n",
        "    cpu_moviepy_params = [\"-movflags\", \"+faststart\", \"-preset\", \"medium\"]\n",
        "    cpu_concat_params = [\"-c:v\", \"libx264\", \"-preset\", \"medium\"]\n",
        "\n",
        "    # NVENC å¿«é€Ÿï¼ˆé€Ÿåº¦ä¼˜å…ˆï¼‰ - ç§»é™¤ä¸å…¼å®¹çš„ -rc å’Œ -cq\n",
        "    fast_nvenc_moviepy = [\"-movflags\", \"+faststart\", \"-preset\", \"p3\"]\n",
        "    fast_nvenc_concat = [\"-c:v\", \"nvenc\", \"-preset\", \"p3\"] # <<< æ›´æ”¹ä¸º 'nvenc'\n",
        "\n",
        "    # NVENC ç”»è´¨ä¼˜å…ˆï¼ˆæ›´é«˜è´¨é‡ï¼‰ - ç§»é™¤ä¸å…¼å®¹çš„ -rc å’Œ -cq\n",
        "    quality_nvenc_moviepy = [\"-movflags\", \"+faststart\", \"-preset\", \"p6\"]\n",
        "    quality_nvenc_concat = [\"-c:v\", \"h264_nvenc\", \"-preset\", \"p6\"]\n",
        "\n",
        "    if mode == \"cpu\":\n",
        "        return \"libx264\", cpu_moviepy_params, cpu_concat_params\n",
        "\n",
        "    if mode == \"fast\":\n",
        "        if _NVENC_AVAILABLE:\n",
        "            return \"h264_nvenc\", fast_nvenc_moviepy, fast_nvenc_concat\n",
        "        else:\n",
        "            return \"libx264\", cpu_moviepy_params, cpu_concat_params\n",
        "\n",
        "    if mode == \"quality\":\n",
        "        if _NVENC_AVAILABLE:\n",
        "            return \"h264_nvenc\", quality_nvenc_moviepy, quality_nvenc_concat\n",
        "        else:\n",
        "            return \"libx264\", cpu_moviepy_params, cpu_concat_params\n",
        "\n",
        "    # mode == \"auto\"\n",
        "    if _NVENC_AVAILABLE:\n",
        "        # é»˜è®¤é€‰æ‹© fast NVENC å½“ auto\n",
        "        return \"h264_nvenc\", fast_nvenc_moviepy, fast_nvenc_concat\n",
        "    else:\n",
        "        return \"libx264\", cpu_moviepy_params, cpu_concat_params\n",
        "\n",
        "# # get config once\n",
        "# _CODEC_FOR_MOVIEPY, _FFMPEG_PARAMS_FOR_MOVIEPY, _CONCAT_PARAMS = get_encoder_config(ENCODER_MODE)\n",
        "# # ç¤ºä¾‹ï¼šå°†ç¼–ç å™¨åç§°ä» 'h264_nvenc' åˆ‡æ¢åˆ° 'nvenc'\n",
        "# _CODEC_FOR_MOVIEPY = \"nvenc\"\n",
        "# _FFMPEG_PARAMS_FOR_MOVIEPY = [\"-movflags\", \"+faststart\", \"-preset\", \"p3\"]\n",
        "# _CONCAT_PARAMS = [\"-c:v\", _CODEC_FOR_MOVIEPY, \"-preset\", \"p3\"]\n",
        "\n",
        "_CODEC_FOR_MOVIEPY, _FFMPEG_PARAMS_FOR_MOVIEPY, _CONCAT_PARAMS = get_encoder_config(ENCODER_MODE)\n",
        "# ----------------------------\n",
        "# ä»¥ä¸Šéƒ¨åˆ†ä»…æ¶‰åŠç¼–ç /ç¡¬ä»¶æ£€æµ‹ï¼ˆä¸æ”¹å˜ä½ åŸæœ‰é€»è¾‘ï¼‰\n",
        "# ----------------------------\n",
        "\n",
        "\n",
        "def wrap_text(text, max_chars_per_line=18):\n",
        "    \"\"\"\n",
        "    æŒ‰å­—æ•°è¿›è¡Œç®€å•çš„è‡ªåŠ¨æ¢è¡Œï¼Œå…¼å®¹ä¸­æ–‡ã€‚\n",
        "    å¯æ ¹æ®å®é™…å­—ä½“å’Œå®½åº¦å¾®è°ƒ max_chars_per_lineã€‚\n",
        "    \"\"\"\n",
        "    text = text.replace(\"\\n\", \" \").strip()\n",
        "    lines = []\n",
        "    while len(text) > max_chars_per_line:\n",
        "        lines.append(text[:max_chars_per_line])\n",
        "        text = text[max_chars_per_line:]\n",
        "    lines.append(text)\n",
        "    return \"\\n\".join(lines)\n",
        "\n",
        "# ---- ä¸»å‡½æ•° ----\n",
        "def process_single_wav(audio_path, image_path):\n",
        "\n",
        "    wav_path = Path(audio_path)\n",
        "\n",
        "    print(f'\\nstart process file [{audio_path}] ...')\n",
        "    output_path = str(wav_path.with_suffix('.mp4'))\n",
        "    srt_path = str(wav_path.with_suffix('.srt'))\n",
        "\n",
        "    if not wav_path.exists():\n",
        "        raise Exception(f'{str(wav_path)} not exists')\n",
        "\n",
        "    if not os.path.exists(srt_path):\n",
        "        raise Exception(f'{srt_path} not exists')\n",
        "\n",
        "    if os.path.exists(output_path):\n",
        "        print(f'output file exists [{output_path}], not process')\n",
        "        return\n",
        "    audio = AudioFileClip(audio_path)\n",
        "    duration = audio.duration\n",
        "    subs = pysrt.open(srt_path)\n",
        "\n",
        "    # èƒŒæ™¯\n",
        "    video_w, video_h = 1280, 720\n",
        "    bg_color = (245, 240, 230)  # ç±³è‰²èƒŒæ™¯\n",
        "    bg = ColorClip(size=(video_w, video_h), color=bg_color).with_duration(duration)\n",
        "\n",
        "    # å›¾ç‰‡åŒºåŸŸï¼ˆå·¦è¾¹ 10%-50%ï¼‰\n",
        "    img_clip = (\n",
        "        ImageClip(image_path)\n",
        "        .resized(height=int(video_h * 0.9))\n",
        "        .with_position((int(video_w * 0.1), \"center\"))\n",
        "        .with_duration(duration)\n",
        "    )\n",
        "\n",
        "    # å­—å¹•åŒºåŸŸï¼ˆå³è¾¹ 50%-90%ï¼‰\n",
        "    text_area_w = int(video_w * 0.45)  # å®½åº¦ä¸ºæ€»å®½åº¦çš„ 40%\n",
        "    text_x_pos = int(video_w * 0.5)   # ä» 50% å¼€å§‹\n",
        "    max_chars_per_line = 14\n",
        "\n",
        "    text_clips = []\n",
        "\n",
        "    pre_end_time = 0\n",
        "    for sub in subs:\n",
        "        txt = sub.text.replace(\"\\n\", \" \")\n",
        "        start = sub.start.ordinal / 1000\n",
        "\n",
        "        if pre_end_time !=0 and start < pre_end_time:\n",
        "            start = pre_end_time\n",
        "        end = sub.end.ordinal / 1000\n",
        "        clip_duration = max(0.05, end - start)\n",
        "\n",
        "        txt = wrap_text(sub.text, max_chars_per_line=max_chars_per_line)\n",
        "        # åˆ›å»ºå­—å¹•ç‰‡æ®µ\n",
        "        try:\n",
        "            text_clip = (\n",
        "                TextClip(\n",
        "                    text=txt + \"\\n\",\n",
        "                    font=FONT_PATH,\n",
        "                    color=\"black\",\n",
        "                    font_size=36,\n",
        "                    size=(text_area_w, 2000),  # æ§åˆ¶æœ€å¤§å®½åº¦ï¼Œå®ç°è‡ªåŠ¨æ¢è¡Œ\n",
        "                    # method=\"label\",\n",
        "                    method=\"caption\",\n",
        "                )\n",
        "                .with_start(start)\n",
        "                .with_duration(clip_duration)\n",
        "                .with_position((text_x_pos, \"center\"))\n",
        "            )\n",
        "        except Exception as e:\n",
        "            print(f\"[TextClip ERROR] {audio_path} | text: {txt} | error: {e}\")\n",
        "            raise Exception(e)\n",
        "        text_clips.append(text_clip)\n",
        "        pre_end_time = end\n",
        "\n",
        "    final = (\n",
        "        CompositeVideoClip([bg, img_clip] + text_clips)\n",
        "        .with_audio(audio)\n",
        "        .with_duration(duration)\n",
        "    )\n",
        "\n",
        "    # ä½¿ç”¨æ£€æµ‹åˆ°æˆ–æŒ‡å®šçš„ç¼–ç å™¨å‚æ•°ï¼ˆä»…å½±å“ç¼–ç å™¨ç›¸å…³é¡¹ï¼‰\n",
        "    final.write_videofile(\n",
        "        output_path,\n",
        "        fps=24,\n",
        "        codec=_CODEC_FOR_MOVIEPY,      # <- å¯èƒ½æ˜¯ \"h264_nvenc\" æˆ– \"libx264\"\n",
        "        audio_codec=\"aac\",\n",
        "        ffmpeg_params=_FFMPEG_PARAMS_FOR_MOVIEPY,\n",
        "        logger=None,\n",
        "        threads=16,\n",
        "    )\n",
        "\n",
        "def combine_mp4(mp4_dir, mp4_regex):\n",
        "\n",
        "    book_stem = Path(mp4_dir).stem\n",
        "\n",
        "    output_path = os.path.join(mp4_dir, f\"{book_stem}_all.mp4\")\n",
        "\n",
        "    list_file = os.path.join(mp4_dir, \"mp4_list.txt\")\n",
        "\n",
        "    mp4_list = get_file_list_sorted(mp4_dir, mp4_regex)\n",
        "    print(mp4_list)\n",
        "\n",
        "    # ç”Ÿæˆä¸­é—´é»‘è‰²è§†é¢‘æ–‡ä»¶ï¼ˆä¸€æ¬¡å³å¯å¤ç”¨ï¼‰\n",
        "    black_clip = \"/Users/larry/Documents/epub/black_0.5s.mp4\"\n",
        "\n",
        "    # ç”Ÿæˆ 0.5 ç§’é»‘è‰²è§†é¢‘ï¼ˆé™éŸ³ï¼‰\n",
        "    if not os.path.exists(black_clip):\n",
        "        subprocess.run([\n",
        "            \"ffmpeg\", \"-f\", \"lavfi\", \"-i\", \"color=c=black:s=1920x1080:d=0.5\",\n",
        "            \"-f\", \"lavfi\", \"-i\", \"anullsrc=r=44100:cl=stereo\",\n",
        "            \"-shortest\", \"-c:v\", \"libx264\", \"-c:a\", \"aac\", \"-y\", black_clip\n",
        "        ])\n",
        "\n",
        "    # åˆ›å»º concat åˆ—è¡¨æ–‡ä»¶\n",
        "\n",
        "    with open(list_file, \"w\") as f:\n",
        "        for i, path in enumerate(mp4_list):\n",
        "            f.write(f\"file '{path}'\\n\")\n",
        "            if i != len(mp4_list) - 1:  # åœ¨ä¸­é—´æ’å…¥ 0.5 ç§’é—´éš”\n",
        "                f.write(f\"file '{black_clip}'\\n\")\n",
        "\n",
        "    # æ‹¼æ¥ï¼šå°†ç¼–ç å™¨å‚æ•°æ’å…¥ subprocess è°ƒç”¨ï¼ˆåªä¿®æ”¹ç¼–ç å™¨ç›¸å…³å‚æ•°ï¼‰\n",
        "    # _CONCAT_PARAMS å·²ç»æ˜¯ç±»ä¼¼: ['-c:v','h264_nvenc','-preset','p4', ...] æˆ– cpu ç‰ˆæœ¬\n",
        "    concat_cmd = [\n",
        "        \"ffmpeg\",\n",
        "        \"-f\", \"concat\",\n",
        "        \"-safe\", \"0\",\n",
        "        # \"-fflags\", \"+genpts\",\n",
        "        \"-i\", list_file,\n",
        "    ]\n",
        "\n",
        "    # æ’å…¥ç¼–ç å‚æ•°\n",
        "    concat_cmd += _CONCAT_PARAMS\n",
        "\n",
        "    # å¸¸ç”¨è¾“å‡ºå‚æ•°ï¼ˆä¸æ”¹å˜åŸæœ‰è¡Œä¸ºï¼‰\n",
        "    concat_cmd += [\n",
        "        \"-pix_fmt\", \"yuv420p\",\n",
        "        \"-c:a\", \"aac\",\n",
        "        \"-threads\", \"16\",\n",
        "        \"-y\", output_path\n",
        "    ]\n",
        "\n",
        "    subprocess.run(concat_cmd)\n",
        "\n",
        "def get_file_list_sorted(wav_src_dir, wav_regex):\n",
        "    pattern = re.compile(wav_regex)\n",
        "\n",
        "    files = [\n",
        "        f for f in os.listdir(wav_src_dir)\n",
        "        if pattern.match(f)\n",
        "    ]\n",
        "\n",
        "    def sort_key(filename):\n",
        "        m = pattern.match(filename)\n",
        "        if m:\n",
        "            second, first = map(int, m.groups())\n",
        "            return (second, first)\n",
        "        return (float('inf'), float('inf'))\n",
        "\n",
        "    sorted_files = sorted(files, key=sort_key)\n",
        "\n",
        "    sorted_paths = [os.path.join(wav_src_dir, f) for f in sorted_files]\n",
        "    return sorted_paths\n",
        "\n",
        "def process_dir(audio_dir, wav_regex, image_path):\n",
        "\n",
        "    for s_path in get_file_list_sorted(audio_dir, wav_regex):\n",
        "        process_single_wav(s_path, image_path)\n",
        "\n",
        "# æµ‹è¯•moviepyçš„è§†é¢‘å¸ƒå±€å’Œæ•ˆæœ\n",
        "def test_font_preview1():\n",
        "    \"\"\"ç”Ÿæˆä¸€ä¸ª 10 ç§’æµ‹è¯•è§†é¢‘ï¼Œå¸ƒå±€ä¸ process_single_wav å®Œå…¨ä¸€è‡´ã€‚\"\"\"\n",
        "\n",
        "    duration = 10\n",
        "    video_w, video_h = 1280, 720\n",
        "\n",
        "    # èƒŒæ™¯\n",
        "    bg_color = (245, 240, 230)\n",
        "    bg = ColorClip(size=(video_w, video_h), color=bg_color).with_duration(duration)\n",
        "\n",
        "    # ----------------------------\n",
        "    # å·¦ä¾§å›¾ç‰‡åŒºåŸŸæ¨¡æ‹Ÿï¼ˆä¸ process_single_wav å¯¹é½)\n",
        "    # ----------------------------\n",
        "    # ç”¨æµ…ç°è‰²æ–¹å—ä»£æ›¿å®é™…å›¾ç‰‡ï¼ˆé¿å…ä¾èµ– image_pathï¼‰\n",
        "    fake_img = (\n",
        "        ColorClip(size=(int(video_w * 0.38), int(video_h * 0.9)), color=(220, 220, 220))\n",
        "        .with_position((int(video_w * 0.1), \"center\"))\n",
        "        .with_duration(duration)\n",
        "    )\n",
        "\n",
        "    # ----------------------------\n",
        "    # å­—å¹•åŒºåŸŸï¼ˆå³ä¾§ 50%-90%ï¼‰â€”â€”å®Œå…¨å¯¹é½ä¸»æµç¨‹\n",
        "    # ----------------------------\n",
        "    text_area_w = int(video_w * 0.45)\n",
        "    text_x_pos = int(video_w * 0.5)\n",
        "    max_chars_per_line = 14\n",
        "\n",
        "    #180å­— ok\n",
        "    txt = \"æ­¤ä¹¦æ ‡å¿—ç€ç¾å›½å­˜åœ¨å¿ƒç†å­¦æœ¬åœŸåŒ–çš„å®Œæˆçš„ã€‚æ­¤ä¹¦æ ‡å¿—ç€ç¾å›½å­˜åœ¨å¿ƒç†å­¦æœ¬åœŸåŒ–çš„å®Œæˆçš„ã€‚æ­¤ä¹¦æ ‡å¿—ç€ç¾å›½å­˜åœ¨å¿ƒç†å­¦æœ¬åœŸåŒ–çš„å®Œæˆçš„ã€‚æ­¤ä¹¦æ ‡å¿—ç€ç¾å›½å­˜åœ¨å¿ƒç†å­¦æœ¬åœŸåŒ–çš„å®Œæˆçš„ã€‚æ­¤ä¹¦æ ‡å¿—ç€ç¾å›½å­˜åœ¨å¿ƒç†å­¦æœ¬åœŸåŒ–çš„å®Œæˆçš„ã€‚æ­¤ä¹¦æ ‡å¿—ç€ç¾å›½å­˜åœ¨å¿ƒç†å­¦æœ¬åœŸåŒ–çš„å®Œæˆçš„ã€‚æ­¤ä¹¦æ ‡å¿—ç€ç¾å›½å­˜åœ¨å¿ƒç†å­¦æœ¬åœŸåŒ–çš„å®Œæˆçš„ã€‚æ­¤ä¹¦æ ‡å¿—ç€ç¾å›½å­˜åœ¨å¿ƒç†å­¦æœ¬åœŸåŒ–çš„å®Œæˆçš„ã€‚æ­¤ä¹¦æ ‡å¿—ç€ç¾å›½å­˜åœ¨å¿ƒç†å­¦æœ¬åœŸåŒ–çš„å®Œæˆçš„ã€‚\"\n",
        "\n",
        "    txt = wrap_text(txt, max_chars_per_line=max_chars_per_line)\n",
        "\n",
        "    text_clip = (\n",
        "        TextClip(\n",
        "            text=txt + \"\\n\",\n",
        "            font=FONT_PATH,\n",
        "            color=\"black\",\n",
        "            font_size=36,\n",
        "            size=(text_area_w, None),\n",
        "            method=\"label\",        # ä¸æ­£å¼æµç¨‹ä¸€è‡´\n",
        "        )\n",
        "        .with_position((text_x_pos, \"center\"))\n",
        "        .with_duration(duration)\n",
        "    )\n",
        "\n",
        "    final = CompositeVideoClip([bg, fake_img, text_clip])\n",
        "\n",
        "    final.write_videofile(\n",
        "        \"font_test.mp4\",\n",
        "        fps=24,\n",
        "        codec=_CODEC_FOR_MOVIEPY\n",
        "    )\n",
        "\n",
        "# æµ‹è¯•æ»šåŠ¨å­—å¹•\n",
        "def test_font_preview(IMAGE_PATH, SRT_PATH):\n",
        "    \"\"\"æŒ‰å¥æ»šåŠ¨ã€å¤šè¡Œæ˜¾ç¤ºã€é«˜äº®å½“å‰å­—å¹•ï¼ˆç¨³å®šç‰ˆï¼‰\"\"\"\n",
        "    video_w, video_h = 1280, 720\n",
        "    text_area_w = int(video_w * 0.45)\n",
        "    text_x_pos = int(video_w * 0.5)\n",
        "    lines_per_block = 6\n",
        "    font_size = 36\n",
        "    line_height = font_size + 10\n",
        "\n",
        "    # èƒŒæ™¯å’Œå›¾ç‰‡\n",
        "    bg = ColorClip(size=(video_w, video_h), color=(245, 240, 230))\n",
        "    img_clip = (\n",
        "        ImageClip(IMAGE_PATH)\n",
        "        .resized(height=int(video_h * 0.9))\n",
        "        .with_position((int(video_w * 0.1), \"center\"))\n",
        "    )\n",
        "\n",
        "    # è¯»å–å­—å¹•\n",
        "    subs = pysrt.open(SRT_PATH)\n",
        "    all_lines = []\n",
        "    for sub in subs:\n",
        "        wrapped = wrap_text(sub.text, max_chars_per_line=14).split(\"\\n\")\n",
        "        all_lines.extend(wrapped)\n",
        "    total_lines = len(all_lines)\n",
        "\n",
        "    text_clips = []\n",
        "\n",
        "    for i, sub in enumerate(subs):\n",
        "        start = sub.start.ordinal / 1000\n",
        "        end = sub.end.ordinal / 1000\n",
        "        duration = end - start\n",
        "\n",
        "        wrapped_lines = wrap_text(sub.text, max_chars_per_line=14).split(\"\\n\")\n",
        "        start_idx = sum(len(wrap_text(s.text, max_chars_per_line=14).split(\"\\n\")) for s in subs[:i])\n",
        "        end_idx = start_idx + len(wrapped_lines)\n",
        "\n",
        "        block_start = max(0, start_idx - lines_per_block // 2)\n",
        "        block_end = min(total_lines, block_start + lines_per_block)\n",
        "        visible_lines = all_lines[block_start:block_end]\n",
        "\n",
        "        # è¡¥ç©ºè¡Œä¿è¯é«˜åº¦å›ºå®š\n",
        "        while len(visible_lines) < lines_per_block:\n",
        "            visible_lines.append(\" \")\n",
        "\n",
        "        # åŸºç¡€æ–‡æœ¬ï¼ˆé»‘è‰²ï¼‰\n",
        "        base_txt = \"\\n\".join(visible_lines)\n",
        "        block_height = lines_per_block * line_height\n",
        "        base_clip = TextClip(text=base_txt, font=FONT_PATH, font_size=font_size,\n",
        "                             color=\"black\", size=(text_area_w, block_height), method=\"label\")\n",
        "        base_clip = base_clip.with_start(start).with_duration(duration).with_position((text_x_pos, video_h//2 - block_height//2))\n",
        "\n",
        "        # é«˜äº®æ–‡æœ¬ï¼ˆé»„è‰²ï¼‰\n",
        "        hl_lines = [\"\"] * lines_per_block\n",
        "        for idx in range(len(visible_lines)):\n",
        "            if start_idx - block_start <= idx < end_idx - block_start:\n",
        "                hl_lines[idx] = visible_lines[idx]\n",
        "        hl_txt = \"\\n\".join(hl_lines)\n",
        "        hl_clip = TextClip(text=hl_txt, font=FONT_PATH, font_size=font_size,\n",
        "                           color=\"yellow\", size=(text_area_w, block_height), method=\"label\")\n",
        "        hl_clip = hl_clip.with_start(start).with_duration(duration).with_position((text_x_pos, video_h//2 - block_height//2))\n",
        "\n",
        "        text_clips.extend([base_clip, hl_clip])\n",
        "\n",
        "    final_duration = subs[-1].end.ordinal / 1000\n",
        "    bg = bg.with_duration(final_duration)\n",
        "    img_clip = img_clip.with_duration(final_duration)\n",
        "    final = CompositeVideoClip([bg, img_clip] + text_clips).with_duration(final_duration)\n",
        "\n",
        "    final.write_videofile(\"data_out/font_test_subtitle_slide_fixed.mp4\", fps=24, codec=_CODEC_FOR_MOVIEPY, ffmpeg_params=_FFMPEG_PARAMS_FOR_MOVIEPY)\n",
        "\n",
        "def run_start():\n",
        "\n",
        "    # book_name = \"fubaiyufanfu\"\n",
        "    book_name = \"tianchaoyaoyuan\"\n",
        "\n",
        "    # test_font_preview()\n",
        "\n",
        "    # test_font_preview(\"/Users/larry/Documents/epub/quanliyuwuzhi.jpg\", \"/Users/larry/github.com/tardigrade-dot/colab-script2/data_src/quanliyuwuzhi-0_0.srt\")\n",
        "\n",
        "    # combine_mp4(f\"/Users/larry/Documents/epub/{book_name}\", r'quanliyuwuzhi-(\\d+)_(\\d+)\\.mp4')\n",
        "\n",
        "    # process_dir(\"/Volumes/sw/MyDrive/xuese2/output\", r'xuese2-(\\d+)_(\\d+)\\.wav', \"/Users/larry/github.com/tardigrade-dot/SenseVoice/data-forcedaligner/cover.jpeg\")\n",
        "\n",
        "    process_dir(\"/content/drive/MyDrive/tianchaoyaoyuan1\", r'tianchaoyaoyuan1-(\\d+)_(\\d+)\\.wav', \"/content/drive/MyDrive/data_src/tianchaoyaoyuan_cover_page.png\")\n",
        "\n",
        "    # process_dir(\"/Users/larry/Documents/epub/fubaiyufanfu\", r'fubaiyufanfu-(\\d+)_(\\d+)\\.wav', \"/Users/larry/Documents/epub/fubaiyufanfu-cover.jpg\")\n",
        "\n",
        "    # process_dir(\"/Users/larry/Documents/epub/quanliyuwuzhi\", r'quanliyuwuzhi-(\\d+)_(\\d+)\\.wav', \"/Users/larry/Documents/epub/quanliyuwuzhi.jpg\")\n",
        "\n",
        "    # process_single_wav(\"/Users/larry/Documents/epub/quanliyuwuzhi/quanliyuwuzhi-2_1.wav\", \"/Users/larry/Documents/epub/quanliyuwuzhi.jpg\")\n",
        "\n",
        "run_start()"
      ],
      "metadata": {
        "id": "2SzQk77-g_cs"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
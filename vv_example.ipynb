{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ee8a005e",
      "metadata": {
        "id": "ee8a005e"
      },
      "outputs": [],
      "source": [
        "!git clone https://github.com/vibevoice-community/VibeVoice"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "rpgTW7Tr6A96"
      },
      "id": "rpgTW7Tr6A96",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!uv pip --quiet install --system -e /content/VibeVoice"
      ],
      "metadata": {
        "id": "vV-pBHBZ6BhC"
      },
      "id": "vV-pBHBZ6BhC",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!uv pip install zh_normalization\n",
        "!uv pip install vibevoice"
      ],
      "metadata": {
        "id": "oOGyJxm8AfO9"
      },
      "id": "oOGyJxm8AfO9",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from vibevoice.modular.modeling_vibevoice_inference import VibeVoiceForConditionalGenerationInference\n",
        "from vibevoice.processor.vibevoice_processor import VibeVoiceProcessor\n",
        "from typing import Dict\n",
        "import torch\n",
        "from transformers.utils import logging\n",
        "import re\n",
        "import os\n",
        "from pathlib import Path\n",
        "from zh_normalization import TextNormalizer\n",
        "\n",
        "logging.set_verbosity_info()\n",
        "logger = logging.get_logger(__name__)\n",
        "\n",
        "sentence_splitter = [\"！\", \"；\", \"？\", \"～\"]\n",
        "char_rep_map = {\n",
        "    \"：\": \",\",\"；\": \",\",\";\": \",\",\"，\": \",\",\"。\": \".\",\"！\": \"!\",\"？\": \"?\",\"·\": \"-\",\n",
        "    \"、\": \",\",\"...\": \"…\",\",,,\": \"…\",\"，，，\": \"…\",\"……\": \"…\",\"“\": \"'\",\"”\": \"'\",\n",
        "    '\"': \"'\",\"‘\": \"'\",\"’\": \"'\",\"（\": \"'\",\"）\": \"'\",\"(\": \"'\",\")\": \"'\",\n",
        "    \"《\": \"'\",\"》\": \"'\",\"【\": \"'\",\"】\": \"'\",\"[\": \"'\",\"]\": \"'\",\"—\": \"-\",\n",
        "    \"～\": \"-\",\"~\": \"-\",\"「\": \"'\",\"」\": \"'\",\":\": \",\",\n",
        "    \"〇\": \"零\",\"○\": \"零\",\"卐\":\"万\"\n",
        "}\n",
        "\n",
        "def replace_chars(full_script, char_rep_map):\n",
        "    result = ''\n",
        "    for char in full_script:\n",
        "        result += char_rep_map.get(char, char)\n",
        "    return result\n",
        "\n",
        "class BookAudioGenerator:\n",
        "    def __init__(self, tts_model, speaker_0, device) -> None:\n",
        "        self.processor = VibeVoiceProcessor.from_pretrained(\n",
        "                tts_model,\n",
        "                device=device\n",
        "            )\n",
        "        model = VibeVoiceForConditionalGenerationInference.from_pretrained(\n",
        "                tts_model,\n",
        "                torch_dtype=torch.bfloat16,\n",
        "                device_map=device,)\n",
        "        model.eval()\n",
        "        model.set_ddpm_inference_steps(num_steps=10)\n",
        "        self.model=model\n",
        "\n",
        "        # self.voice_samples=[speaker_0]\n",
        "        self.default_prefix=\"Speaker 1:\"\n",
        "        self.tn = TextNormalizer()\n",
        "        self.default_speaker = \"旁白\"\n",
        "        self.max_length_times = 2.5 # 2.6\n",
        "\n",
        "    def batch_process(self, i_file, batch_size, process_size):\n",
        "        def _read_file():\n",
        "            _lines = []\n",
        "            with open(i_file, 'r', encoding='utf-8') as f: # 按行分割, 保证在一个段落的内容都放在一个输入中, 避免从中间拆分\n",
        "                _lines = f.read().splitlines()\n",
        "            if not _lines:\n",
        "                raise Exception(f'not content in {i_file}')\n",
        "\n",
        "            results = []  # 存放一批(batch_size)的结果\n",
        "            current_lines = []  # 当前正在积累的块\n",
        "            current_length = 0  # 当前块的字符总长度\n",
        "\n",
        "            for _line in _lines:\n",
        "                if _line:\n",
        "                    current_lines.append(_line)\n",
        "                    current_length += len(_line)\n",
        "                    if current_length >= process_size:\n",
        "                        results.append(current_lines)\n",
        "                        current_lines = []\n",
        "                        current_length = 0\n",
        "                        if len(results) == batch_size:\n",
        "                            yield results\n",
        "                            results = []\n",
        "            if current_lines:\n",
        "                results.append(current_lines)\n",
        "            if results:\n",
        "                yield results\n",
        "\n",
        "        batch_index = 0\n",
        "        for batch in _read_file():\n",
        "            processed_batch = []\n",
        "            for sub_list in batch:\n",
        "                processed_sub_list = []\n",
        "\n",
        "                for item in sub_list:\n",
        "                    stripped_item = item.strip()\n",
        "                    if stripped_item:\n",
        "                        stripped_item.split() # 将一个段落拆分,避免一句话中内容太多,导致输出语音语速变快\n",
        "                        processed_sub_list.extend(self.split_sentence(stripped_item))\n",
        "\n",
        "                processed_batch.append(processed_sub_list)\n",
        "            yield processed_batch, batch_index\n",
        "            batch_index += 1\n",
        "\n",
        "    def split_sentence(self, sentence):\n",
        "        pattern = r'([.?!？！…])\\s*'\n",
        "        parts = re.split(pattern, sentence)\n",
        "        sentences = []\n",
        "        current_sentence = \"\"\n",
        "        for part in parts:\n",
        "            if part is None or not part.strip():\n",
        "                continue\n",
        "            current_sentence += part\n",
        "            if part in ('.', '?', '!'):\n",
        "                sentences.append(current_sentence.strip())\n",
        "                current_sentence = \"\"\n",
        "        if current_sentence.strip():\n",
        "            sentences.append(current_sentence.strip())\n",
        "        return sentences\n",
        "\n",
        "    def _tts_generate(self, to_tts_batch, voice_sample):\n",
        "        inputs = self.processor(\n",
        "            text=to_tts_batch,\n",
        "            voice_samples=voice_sample,\n",
        "            padding=True,\n",
        "            return_tensors=\"pt\",\n",
        "            return_attention_mask=True,\n",
        "        )\n",
        "\n",
        "        outputs = self.model.generate(\n",
        "            **inputs,\n",
        "            max_new_tokens=None,\n",
        "            cfg_scale=1.3,\n",
        "            tokenizer=self.processor.tokenizer,\n",
        "            # generation_config={'do_sample': True, 'temperature': 0.99, 'top_p': 0.99, 'top_k': 3},\n",
        "            generation_config={'do_sample': False},\n",
        "            verbose=True,\n",
        "            max_length_times=self.max_length_times, #default 2\n",
        "        )\n",
        "        return outputs\n",
        "\n",
        "    def txt_normlize(self, txt):\n",
        "        return self.tn.normalize_sentence(txt)\n",
        "\n",
        "    def tts_txt_preprocess(self, txt):\n",
        "\n",
        "        chinese_pattern = r\"（.*?）\"\n",
        "        english_pattern = r\"\\([^)]*\\)\"\n",
        "\n",
        "        combined_pattern = f\"{chinese_pattern}|{english_pattern}\"\n",
        "        _txt = re.sub(combined_pattern, \"\", txt)# 规范化, 替换中文符号, 根据vibevoice文档, 建议使用英语标点符号\n",
        "        _txt = self.default_prefix + replace_chars(_txt, char_rep_map)\n",
        "        return _txt\n",
        "\n",
        "    def gererator_speech_with_default_single_voice(\n",
        "            self,\n",
        "            chunk,\n",
        "            batch_index,\n",
        "            single_speaker,\n",
        "            output_dir\n",
        "            ):\n",
        "\n",
        "        norm_tts_batch = [\n",
        "            [self.txt_normlize(item) for item in row] #保存规范化的内容到txt,同时保留原本的中文标点符号\n",
        "            for row in chunk\n",
        "        ]\n",
        "        to_tts_batch = [\n",
        "            \"\\n\".join([\n",
        "                self.tts_txt_preprocess(item) for item in s_batch\n",
        "            ])\n",
        "\n",
        "            for s_batch in norm_tts_batch\n",
        "            ]\n",
        "\n",
        "        output_stem = output_path_wav = f\"{output_dir}/{project_name}-{batch_index}\"\n",
        "        output_path_wav = f\"{output_stem}_0.wav\"\n",
        "        if os.path.exists(output_path_wav):\n",
        "            logger.warning(f'⚠️ file {output_path_wav} exists, so batch will not process.')\n",
        "            return\n",
        "\n",
        "        outputs = self._tts_generate(to_tts_batch, [[single_speaker]] * len(chunk))\n",
        "        for check in outputs.reach_max_step_sample.tolist():\n",
        "            if check:\n",
        "                logger.warning(f'⚠️  reach max length, audio may cut up, you may increase [max_length_times] and current is [{self.max_length_times}]')\n",
        "\n",
        "        for _index, (output_speech, txt) in enumerate(zip(outputs.speech_outputs, chunk)):\n",
        "\n",
        "            output_path_wav = f\"{output_stem}_{_index}.wav\"\n",
        "            output_path_txt = f\"{output_stem}_{_index}.txt\"\n",
        "\n",
        "            output_path = Path(output_path_txt)\n",
        "            output_path.parent.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "            self.processor.save_audio(\n",
        "                output_speech,\n",
        "                output_path=output_path_wav,\n",
        "            )\n",
        "            output_path.write_text(\"\\n\".join(txt), encoding='utf-8')\n",
        "            logger.info(f'finish process ouput file : {output_path_wav} \\n {output_path_txt}')\n",
        "\n",
        "    def generate(self, to_tts_file, output_dir, single_speaker, batch_size = 4, process_size = 9000):\n",
        "        for _b, _i in self.batch_process(to_tts_file, batch_size, process_size):\n",
        "            self.gererator_speech_with_default_single_voice(_b, _i, single_speaker, output_dir)\n",
        "\n",
        "    def generate_single_dialog(self, to_tts_file, txt_speeker, speeker_voice):\n",
        "\n",
        "        with open(to_tts_file, 'r', encoding='utf-8') as f:\n",
        "            _lines = f.read().splitlines()\n",
        "        output_path_wav = Path(to_tts_file).with_suffix(\".wav\")\n",
        "\n",
        "        speeker_voice_x = [f\"Speaker {i+1}\" for i, speaker in enumerate(txt_speeker)]\n",
        "        speaker_map: Dict[str, str] = dict(zip(txt_speeker, speeker_voice_x))\n",
        "\n",
        "        SPEAKER_PATTERN = re.compile(r'^([^:]+):')\n",
        "\n",
        "        to_tts_batch = []\n",
        "        pre_speaker = self.default_speaker\n",
        "        for item in _lines:\n",
        "            if item:\n",
        "                match = SPEAKER_PATTERN.match(item)\n",
        "                if match:\n",
        "                    speaker_name = match.group(1).strip()\n",
        "                    selected_prefix = speaker_map.get(speaker_name, self.default_speaker[0])\n",
        "                    item_content = item[match.end():].strip() # 提取冒号后的内容\n",
        "                    new_line = selected_prefix + \": \" + item_content\n",
        "                    pre_speaker = speaker_name\n",
        "                else:\n",
        "                    speaker_name = pre_speaker\n",
        "                    new_line = speaker_map.get(speaker_name, self.default_speaker[0]) + \": \" + item\n",
        "                to_tts_batch.append(new_line)\n",
        "\n",
        "        to_tts_batch = [\"\\n\".join(to_tts_batch)]\n",
        "\n",
        "        outputs = self._tts_generate(to_tts_batch, speeker_voice)\n",
        "        self.processor.save_audio(\n",
        "            outputs.speech_outputs[0],\n",
        "            output_path=output_path_wav,\n",
        "        )\n",
        "\n",
        "    def generate_single(self, to_tts_file):\n",
        "        with open(to_tts_file, 'r', encoding='utf-8') as f:\n",
        "            _lines = f.read().splitlines()\n",
        "\n",
        "        output_path_wav = Path(to_tts_file).with_suffix(\".wav\")\n",
        "        to_tts_txt = [self.default_prefix + item for item in _lines]\n",
        "        to_tts_txt = \"\\n\".join(to_tts_txt)\n",
        "\n",
        "        outputs = self._tts_generate(to_tts_txt, [self.voice_samples])\n",
        "        self.processor.save_audio(\n",
        "            outputs.speech_outputs[0],\n",
        "            output_path=output_path_wav,\n",
        "        )\n",
        "\n",
        "env_type = \"colab\" # colab modelscope local\n",
        "\n",
        "drive_dir = None\n",
        "device = None\n",
        "model_dir = None\n",
        "\n",
        "match env_type:\n",
        "    case \"local\":\n",
        "        drive_dir = \"/Volumes/sw/MyDrive\"\n",
        "        model_dir = \"/Volumes/sw/pretrained_models\"\n",
        "        torch.set_float32_matmul_precision(\"high\")\n",
        "        device = \"mps\"\n",
        "    case \"modelscope\":\n",
        "        drive_dir = \"/mnt/workspace\"\n",
        "        model_dir = \"/mnt/workspace/pretrained_models\"\n",
        "        device = \"cuda\"\n",
        "    case \"colab\":\n",
        "        drive_dir = \"/content/drive/MyDrive\"\n",
        "        model_name = \"tardigrade-doc/VibeVoice-1.5B-ft\"\n",
        "        # model_name = \"microsoft/VibeVoice-1.5B\"\n",
        "        device = \"cuda\"\n",
        "    case _:\n",
        "        raise Exception(f\"not supported env {env_type}\")\n",
        "\n",
        "\n",
        "input_file = f\"{drive_dir}/data_src/kenengxing.txt\"\n",
        "speaker_phi0 = f\"{drive_dir}/data_src/qinsheng-30s.wav\"\n",
        "\n",
        "input_file_path = Path(input_file)\n",
        "project_name = input_file_path.stem\n",
        "\n",
        "output_dir = f\"{drive_dir}/{project_name}\"\n",
        "\n",
        "bookAudioGen = BookAudioGenerator(\n",
        "    model_name,\n",
        "    speaker_phi0,\n",
        "    device)\n",
        "\n",
        "bookAudioGen.generate(input_file, output_dir, speaker_phi0, 2, 5000)\n",
        "\n",
        "# 针对某个已经经过上述批量处理后,某个txt对应的wav存在问题的重新生成.\n",
        "# bookAudioGen.generate_single(\"/Volumes/sw/MyDrive/zhengzhi1/output/zhengzhi1-4_2.txt\", [speaker_phi0])\n",
        "\n",
        "# bookAudioGen.generate_single(\"/Volumes/sw/tmp/zhengzhi1-5_4.txt\")\n",
        "\n",
        "# bookAudioGen.generate_single_dialog(\n",
        "#     \"/Users/larry/github.com/tardigrade-dot/colab-script/data_src/sugeladizhisi_part1.txt\",\n",
        "#     [\"旁白\", \"欧\", \"苏\"],\n",
        "#     [f\"{drive_dir}/data_src/youyi.wav\", f\"{drive_dir}/data_src/sample_zhongdong.wav\", f\"{drive_dir}/data_src/gdg_voice_06.wav\"])\n"
      ],
      "metadata": {
        "id": "N6nKYjf36SS-"
      },
      "id": "N6nKYjf36SS-",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.14"
    },
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "L4"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}